<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Introduction to GPUs - Introduction to R, MATLAB, and Julia in HPC</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../assets/_markdown_exec_pyodide.css" rel="stylesheet" />
        <link href="../../assets/_markdown_exec_ansi.css" rel="stylesheet" />
        <link href="../../assets/_mkdocstrings.css" rel="stylesheet" />
        <link href="../../css/extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Introduction to GPUs";
        var mkdocs_page_input_path = "advanced/gpus.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../..">
          <img src="../../img/new-logo.png" class="logo" alt="Logo"/>
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Overview</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Prequisites</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../prereqs/">Prerequisites</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../preparations_account/">Preparations with course project</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../preparations_cluster/">Preparations on the cluster</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Common</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../common/login/">Login</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../projects/">Projects</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../common/use_tarball/">Use the tarball</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../common/use_text_editor/">Use a text editor</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../common/hpc_clusters/">HPC clusters</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../common/other_courses/">Other courses</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../common/on-demand/">Desktop on demand</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">R</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../r/schedule/">Schedule</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../r/intro/">Intro</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../r/load_run/">Load and run</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../r/packages/">Packages</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../r/batch/">Batch</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../r/interactive/">Interactive work on the compute nodes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../r/rstudio/">RStudio</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../r/summary/">Summary</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../r/evaluation/">Evaluation</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">MATLAB</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../matlab/schedule/">Schedule</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../matlab/intro-matlab/">Intro</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../matlab/load_runMatlab/">Load and run</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../matlab/slurmMatlab/">MATLAB terminal and Slurm</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../matlab/interactive/">Interactive work on the compute nodes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../matlab/MatlabGUIslurm/">MATLAB GUI and batch jobs</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../matlab/matlab-addons/">MATLAB Add-Ons</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../matlab/matlab-summary/">Summary</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../matlab/evaluation-matlab/">Evaluation</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Julia</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../julia/schedule/">Schedule</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../julia/intro/">Intro</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../julia/load_run/">Load and run</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../julia/environments_packages/">Environments and packages</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../julia/batch/">Batch jobs</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../julia/interactive/">Interactive work on the compute nodes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../julia/summary/">Summary</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../julia/evaluation-julia/">Evaluation</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Advanced</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../schedule/">Schedule</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../parallel_computing/">Parallel computing</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../thread_parallelism/">Thread parallelism</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../distributed_parallelism/">Distributed parallelism</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../big_data_managers/">Big data</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">Introduction to GPUs</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#gpus-on-c3se-uppmax-hpc2n-lunarc-nsc-and-pdc-systems">GPUs on C3SE, UPPMAX, HPC2N, LUNARC, NSC, and PDC systems</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#deploying-gpus">Deploying GPUs</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#r">R</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#matlab">MATLAB</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#julia">Julia</a>
    </li>
        </ul>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Machine Learning</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../ML/">Introduction</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../MLR/">With R</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../MLjulia/">With Julia</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../MLmatlab/">With MATLAB</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../summary/">Summary</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../evaluation/">Evaluation</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Misc</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../evaluations/">Evaluations</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../lesson_plans/">Lesson plans</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../reflections/">Reflections</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Extra reading</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../r/morepackages/">More about R packages</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../matlab/extra/">More about Matlab</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../julia/extra/">More about Julia</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">Introduction to R, MATLAB, and Julia in HPC</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Advanced</li>
      <li class="breadcrumb-item active">Introduction to GPUs</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/UPPMAX/R-matlab-julia-HPC/blob/main/docs/advanced/gpus.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="using-gpus">Using GPUs<a class="headerlink" href="#using-gpus" title="Anchor link to this section for reference">&para;</a></h1>
<div class="admonition note">
<p class="admonition-title">Questions</p>
<ul>
<li>What is GPU acceleration?</li>
<li>How to enable GPUs?</li>
<li>How to deploy GPUs at HPC2N, UPPMAX, LUNARC, NSC, PDC and C3SE?</li>
</ul>
</div>
<div class="admonition note">
<p class="admonition-title">Objectives</p>
<ul>
<li>Get an intro to common schemes for GPU code acceleration</li>
<li>Learn about the GPU nodes at HPC2N, UPPMAX, LUNARC, NSC, PDC, and C3SE</li>
<li>Learn how to make a batch script asking for GPU nodes at HPC2N, UPPMAX, LUNARC, NSC, PDC, and C3SE</li>
</ul>
</div>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Anchor link to this section for reference">&para;</a></h2>
<p>In order to understand the capabilities of a GPU, it is instructive to compare a pure CPU architecture with a GPU based architecture. Here, there is a schematics of the former:</p>
<div class="admonition note">
<p class="admonition-title"> </p>
<p><img alt="AMD Zen4 CPU" src="../../img/AMD-Zen4-CPU-b-cn1701.png" /></p>
<p>Pure CPU architecture (single node). In the present case there are 256 cores, each with its own cache memory (LX). There is a shared memory (~378 GB/NUMA node) for all these cores. This is an AMD Zen4 node.</p>
<p>The base frequency is 2.25 GHz, but it can boost up to 3.1 GHz.</p>
</div>
<p>As for the GPU architecture, a GPU card of type Ada Lovelace (like the L40s) looks like this:</p>
<div class="admonition note">
<p class="admonition-title"> </p>
<p><img align:="align:" alt="Ada Lovelace GPU" center="center" src="../../img/lovelace-diagram.png" /></p>
<p>Note: The AD102 GPU also includes 288 FP64 Cores (2 per SM) which are not depicted in the above diagram. The FP64 TFLOP rate is 1/64th the TFLOP rate of FP32 operations. The small number of FP64 Cores are included to ensure any programs with FP64 code operate correctly, including FP64 Tensor Core code.</p>
<p>This is a single GPU engine of a L40s card. There are 12 Graphics Processing Clusters (GPCs), 72 Texture Processing Clusters (TPCs), 144 Streaming Multiprocessors (SMs), and a 384-bit memory interface with 12 32-bit memory controllers).</p>
<p>On the diagram, each green dot represents a CUDA core (single precision), while the yellow are RT cores and blue Tensor cores. The cores are arranged in the slots called SMs in the figure. Cores in the same SM share some local and fast cache memory.</p>
</div>
<div class="admonition note">
<p class="admonition-title">GPCs</p>
<p><img alt="GPC" src="../../img/GPC-with-raster-engine.png" /></p>
<p>The GPC is the dominant high-level hardware block. Each GPC includes a dedicated Raster Engine, two Raster Operations (ROPs) partitions, with each partition containing eight individual ROP units, and six TPCs. Each TPC includes one PolyMorph Engine and two SMs.</p>
<p>Each SM contain 128 CUDA Cores, one Ada Third-Generation RT Core, four Ada Fourth-Generation Tensor Cores, four Texture Units, a 256 KB Register File, and 128 KB of L1/Shared Memory, which can be configured for different memory sizes depending on the needs of the graphics or compute workload.</p>
</div>
<p>In a typical cluster, some GPUs are attached to a single node resulting in a CPU-GPU hybrid architecture. The CPU component is called the host and the GPU part the device.</p>
<div class="admonition note">
<p class="admonition-title">One possible layout</p>
<p>Kebnekaise, AMD Zen4 node with L40s GPU</p>
<p><img alt="AMD-Zen4-L40s-GPU" src="../../img/AMD-Zen4-GPU-1605.png" /></p>
<p>Schematics of a hybrid CPU-GPU architecture. A GPU L40s card is attached to a NUMA island which in turn contains 24 cores (AMD Zen4 CPU node with 48 cores total). The NUMA island and the GPUs are connected through a PCI-E interconnect which makes the data transfer between both components rather slow.</p>
</div>
<p>We can characterize the CPU and GPU performance with two quantities: the <strong>latency</strong> and the <strong>throughput</strong>.</p>
<ul>
<li><strong>Latency</strong> refers to the time spent in a sole computation.</li>
<li><strong>Throughput</strong> denotes the number of computations that can be performed in parallel. Then, we can say that a CPU has low latency (able to do fast computations) but low throughput (only a few computations simultaneously).</li>
</ul>
<p>In the case of GPUs, the latency is high and the throughput is also high. We can visualize the behavior of the CPUs and GPUs with cars as in the figure below. A CPU would be compact road where only a few racing cars can drive whereas a GPU would be a broader road where plenty of slow cars can drive.</p>
<p><img alt="CPU-GPU-cars" src="../../img/cpu-gpu-highway.png" /></p>
<p>Cars and roads analogy for the CPU and GPU behavior. The compact road is analogous to the CPU (low latency, low throughput) and the broader road is analogous to the GPU (high latency, high throughput).</p>
<p>Not every program is suitable for GPU acceleration. GPUs process simple functions rapidly, and are best suited for repetitive and highly-parallel computing tasks. GPUs were originally designed to render high-resolution images and video concurrently and fast, but since they can perform parallel operations on multiple sets of data, they are also often used for other, non-graphical tasks. Common uses are machine learning and scientific computation were the GPUs can take advantage of massive parallelism.</p>
<ul>
<li>Many R packages are not CUDA aware, but some have been written specifically with GPUs in mind.</li>
<li>Many Julia packages are not CUDA aware. The CUDA.jl package is the main programming interface for working with Nvidia GPUs.</li>
<li>Matlab does have support for computing on GPUs, but you need to write functions that support GPU execution. Many functions in Matlab run automatically on a GPU if you supply a gpuArray data argument. GPU computing in MATLAB requires Parallel Computing Toolbox. Information here: <a href="https://www.mathworks.com/help/parallel-computing/run-matlab-functions-on-a-gpu.html" target="_blank">Run MATLAB Functions on a GPU</a>.</li>
</ul>
<p>One of the most common use of GPUs with and Julia is for machine learning or deep learning.</p>
<h2 id="gpus-on-c3se-uppmax-hpc2n-lunarc-nsc-and-pdc-systems">GPUs on C3SE, UPPMAX, HPC2N, LUNARC, NSC, and PDC systems<a class="headerlink" href="#gpus-on-c3se-uppmax-hpc2n-lunarc-nsc-and-pdc-systems" title="Anchor link to this section for reference">&para;</a></h2>
<p>There are generally either not GPUs on the login nodes or they cannot be accessed for computations.
To use them you need to either launch an interactive job or submit a batch job.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:6"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><input id="__tabbed_1_3" name="__tabbed_1" type="radio" /><input id="__tabbed_1_4" name="__tabbed_1" type="radio" /><input id="__tabbed_1_5" name="__tabbed_1" type="radio" /><input id="__tabbed_1_6" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">C3SE</label><label for="__tabbed_1_2">NSC</label><label for="__tabbed_1_3">PDC</label><label for="__tabbed_1_4">UPPMAX</label><label for="__tabbed_1_5">HPC2N</label><label for="__tabbed_1_6">LUNARC</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>Alvis is meant for GPU jobs. There is no node-sharing on multi-node jobs (<code>--exclusive</code> is automatic).</p>
<p>NOTE: Requesting -N 1 does not mean 1 full node</p>
<p>You would need to add this to your batch script:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="c1">#SBATCH -p alvis</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="c1">#SBATCH -N &lt;nodes&gt;</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="c1">#SBATCH --gpus-per-node=&lt;type&gt;:x</span>
</span></code></pre></div>
<p>where <code>&lt;type&gt;</code> is one of</p>
<ul>
<li>V100</li>
<li>T4</li>
<li>A100</li>
</ul>
<p>and <code>x</code> is number of GPU cards</p>
<ul>
<li>1-4 for V100</li>
<li>1-8 for T4</li>
<li>1-4 for A100</li>
</ul>
</div>
<div class="tabbed-block">
<p>Tetralith has Nvidia T4 GPUs. In order to access them, add this to your batch script or interactive job:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="c1">#SBATCH -n 1</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="c1">#SBATCH -c 32</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="c1">#SBATCH --gpus-per-task=1</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p>Dardel has AMD Instinct™ MI250X GPU chips. In order to access them, add this to your batch script or interactive job:</p>
<p>You need to add this to your batch script (or interactive job) in order to use them:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="c1">#SBATCH -N 1</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="c1">#SBATCH --ntasks-per-node=1</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="c1">#SBATCH -p gpu</span>
</span></code></pre></div>
<p>NOTE: the fact that Dardel has AMD GPUs means that CUDA-enabled packages will not run! You need something like hip.</p>
</div>
<div class="tabbed-block">
<p>Rackham’s compute nodes do not have GPUs. You need to use Snowy for that.
The new cluster Pelle has GPUs.</p>
<p>On Pelle, you need to use this batch command:</p>
<ul>
<li>for L40s GPUs (up to 10 GPU cards)</li>
</ul>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="c1">#SBATCH -p gpu</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="c1">#SBATCH --gpus:l40s:&lt;number of GPUs&gt;</span>
</span></code></pre></div>
<p>or for H100 GPUs (up to 2 GPU cards)</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="c1">#SBATCH -p gpu</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="c1">#SBATCH --gpus=h100:&lt;number of GPUs&gt;</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p>Kebnekaise&rsquo;s GPU nodes are considered a separate resource, and the regular compute nodes do not have GPUs.</p>
<p>Kebnekaise has a great many different types of GPUs:</p>
<ul>
<li>V100 (2 cards/node)</li>
<li>A40 (8 cards/node)</li>
<li>A6000 (2 cards/node)</li>
<li>L40s (2 or 6 cards/node)</li>
<li>A100 (2 cards/node)</li>
<li>H100 (4 cards/node)</li>
<li>MI100 (2 cards/node)</li>
</ul>
<p>To access them, you need to use this to the batch system:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="c1">#SBATCH --gpus=x</span>
</span></code></pre></div>
<p>where x is the number of GPU cards you want. Above are given how many are on each type, so you can ask for up to that number.</p>
<p>In addition, you need to add this to the batch system:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="c1">#SBATCH -C &lt;type&gt;</span>
</span></code></pre></div>
<p>where type is</p>
<ul>
<li>v100</li>
<li>a40</li>
<li>a6000</li>
<li>l40s</li>
<li>a100</li>
<li>h100</li>
<li>mi100</li>
</ul>
<p>For more information, see HPC2N&rsquo;s guide to the different parts of the batch system: <a href="https://docs.hpc2n.umu.se/documentation/batchsystem/resources/" target="_blank">https://docs.hpc2n.umu.se/documentation/batchsystem/resources/</a></p>
</div>
<div class="tabbed-block">
<p>LUNARC has Nvidia A100 GPUs and Nvidia A40 GPUs, but the latter ones are reserved for interactive graphics work on the on-demand system, and Slurm jobs should not be submitted to them.</p>
<p>Thus in order to use the A100 GPUs on Cosmos, add this to your batch script:</p>
<p>A100 GPUs on AMD nodes:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="c1">#SBATCH -p gpua100</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="c1">#SBATCH --gres=gpu:1</span>
</span></code></pre></div>
<p>These nodes are configured as exclusive access and will not be shared between users. User projects will be charged for the entire node (48 cores). A job on a node will also have access to all memory on the node.</p>
<p>A100 GPUs on Intel nodes:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="c1">#SBATCH -p gpua100i</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="c1">#SBATCH --gres=gpu:&lt;number&gt;</span>
</span></code></pre></div>
<p>where <code>&lt;number&gt;</code> is 1 or 2 (Two of the nodes have 1 GPU and two have 2 GPUs).</p>
</div>
</div>
</div>
<h2 id="deploying-gpus">Deploying GPUs<a class="headerlink" href="#deploying-gpus" title="Anchor link to this section for reference">&para;</a></h2>
<p>As mentioned, you need a batch job or an interactive job (could also be through Open OnDemand or from inside MATLAB) to use the GPUs.</p>
<h3 id="r">R<a class="headerlink" href="#r" title="Anchor link to this section for reference">&para;</a></h3>
<p>Here follows an example of a batch script that allocates GPUs. This is for an R job, but it is done similarly for Julia and Matlab.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:6"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><input id="__tabbed_2_3" name="__tabbed_2" type="radio" /><input id="__tabbed_2_4" name="__tabbed_2" type="radio" /><input id="__tabbed_2_5" name="__tabbed_2" type="radio" /><input id="__tabbed_2_6" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">NSC</label><label for="__tabbed_2_2">PDC</label><label for="__tabbed_2_3">C3SE</label><label for="__tabbed_2_4">UPPMAX</label><label for="__tabbed_2_5">HPC2N</label><label for="__tabbed_2_6">LUNARC</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="ch">#!/bin/bash</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="c1"># Remember to change this to your own project ID after the course!</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="c1">#SBATCH -A naiss2025-22-934</span>
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a><span class="c1"># Asking for runtime: hours, minutes, seconds. At most 1 week</span>
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a><span class="c1">#SBATCH --time=HHH:MM:SS</span>
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a><span class="c1"># Ask for resources, including GPU resources</span>
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a><span class="c1">#SBATCH -n 1</span>
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a><span class="c1">#SBATCH -c 32</span>
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a><span class="c1">#SBATCH --gpus-per-task=1</span>
</span><span id="__span-9-10"><a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a>
</span><span id="__span-9-11"><a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a><span class="c1"># Remove any loaded modules and load the ones we need</span>
</span><span id="__span-9-12"><a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a>module<span class="w"> </span>purge<span class="w">  </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-9-13"><a id="__codelineno-9-13" name="__codelineno-9-13" href="#__codelineno-9-13"></a>module<span class="w"> </span>load<span class="w"> </span>R/4.4.0-hpc1-gcc-11.3.0-bare
</span><span id="__span-9-14"><a id="__codelineno-9-14" name="__codelineno-9-14" href="#__codelineno-9-14"></a>
</span><span id="__span-9-15"><a id="__codelineno-9-15" name="__codelineno-9-15" href="#__codelineno-9-15"></a>R<span class="w"> </span>--no-save<span class="w"> </span>--no-restore<span class="w"> </span>-f<span class="w"> </span>MY-R-GPU-SCRIPT.R
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="ch">#!/bin/bash -l</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="c1"># Remember to change this to your own project ID after the course!</span>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="c1">#SBATCH -A naiss2025-22-934</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="c1"># Asking for runtime: hours, minutes, seconds. At most 1 week</span>
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a><span class="c1">#SBATCH --time=HHH:MM:SS</span>
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a><span class="c1"># Ask for resources, including GPU resources</span>
</span><span id="__span-10-7"><a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a><span class="c1">#SBATCH -N 1</span>
</span><span id="__span-10-8"><a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a><span class="c1">#SBATCH --ntasks-per-node=1</span>
</span><span id="__span-10-9"><a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a><span class="c1">#SBATCH -p gpu</span>
</span><span id="__span-10-10"><a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a>
</span><span id="__span-10-11"><a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a>module<span class="w"> </span>load<span class="w"> </span>PDC/23.12<span class="w"> </span>R/4.4.1-cpeGNU-23.12
</span><span id="__span-10-12"><a id="__codelineno-10-12" name="__codelineno-10-12" href="#__codelineno-10-12"></a>module<span class="w"> </span>load<span class="w"> </span>rocm/5.7.0
</span><span id="__span-10-13"><a id="__codelineno-10-13" name="__codelineno-10-13" href="#__codelineno-10-13"></a><span class="c1">#module load craype-accel-amd-gfx90a</span>
</span><span id="__span-10-14"><a id="__codelineno-10-14" name="__codelineno-10-14" href="#__codelineno-10-14"></a><span class="c1">#module load cpeGNU/23.12</span>
</span><span id="__span-10-15"><a id="__codelineno-10-15" name="__codelineno-10-15" href="#__codelineno-10-15"></a>R<span class="w"> </span>--no-save<span class="w"> </span>--no-restore<span class="w"> </span>-f<span class="w"> </span>MY-R-GPU-SCRIPT.R
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="ch">#!/bin/bash</span>
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="c1"># Remember to change this to your own project ID after the course!</span>
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="c1">#SBATCH -A NAISS2025-22-934</span>
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a><span class="c1">#SBATCH -t HHH:MM:SS</span>
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a><span class="c1">#SBATCH -p alvis</span>
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a><span class="c1">#SBATCH -N 1 --gpus-per-node=T4:4</span>
</span><span id="__span-11-7"><a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>
</span><span id="__span-11-8"><a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>ml<span class="w"> </span>purge<span class="w"> </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-11-9"><a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a>module<span class="w"> </span>load<span class="w"> </span>R/4.2.1-foss-2022a<span class="w"> </span>CUDA/12.9.1
</span><span id="__span-11-10"><a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>
</span><span id="__span-11-11"><a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a>R<span class="w"> </span>--no-save<span class="w"> </span>--no-restore<span class="w"> </span>-f<span class="w"> </span>MY-R-GPU-SCRIPT.R
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p><strong>Rackham/Snowy</strong>:  </p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="ch">#!/bin/bash -l </span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="c1">#SBATCH -A uppmax2025-Y-ZZZ</span>
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a><span class="c1">#Asking for runtime: hours, minutes, seconds. At most 1 week</span>
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="c1">#SBATCH -t HHH:MM:SS</span>
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a><span class="c1">#SBATCH --exclusive</span>
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a><span class="c1">#SBATCH -p node</span>
</span><span id="__span-12-7"><a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a><span class="c1">#SBATCH -N 1</span>
</span><span id="__span-12-8"><a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a><span class="c1">#SBATCH -M snowy</span>
</span><span id="__span-12-9"><a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a><span class="c1">#SBATCH --gpus=1</span>
</span><span id="__span-12-10"><a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a><span class="c1">#SBATCH --gpus-per-node=1</span>
</span><span id="__span-12-11"><a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a><span class="c1">#Writing output and error files</span>
</span><span id="__span-12-12"><a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a><span class="c1">#SBATCH --output=output%J.out</span>
</span><span id="__span-12-13"><a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a><span class="c1">#SBATCH --error=error%J.error</span>
</span><span id="__span-12-14"><a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a>
</span><span id="__span-12-15"><a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a>ml<span class="w"> </span>purge<span class="w"> </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-12-16"><a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a>ml<span class="w"> </span>uppmax<span class="w"> </span>R/4.1.1<span class="w"> </span>R_packages/4.1.1
</span><span id="__span-12-17"><a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a>
</span><span id="__span-12-18"><a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a>R<span class="w"> </span>--no-save<span class="w"> </span>--no-restore<span class="w"> </span>-f<span class="w"> </span>MY-R-GPU-SCRIPT.R
</span></code></pre></div>
<p><strong>Pelle (1 L40s)</strong>:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="ch">#!/bin/bash -l</span>
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a><span class="c1">#SBATCH -A uppmax2025-Y-ZZZ </span>
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a><span class="c1">#Asking for runtime: hours, minutes, seconds. At most 1 week</span>
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a><span class="c1">#SBATCH -t HHH:MM:SS</span>
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a><span class="c1">#SBATCH -p gpu</span>
</span><span id="__span-13-6"><a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a><span class="c1">#SBATCH --gpus:l40s:1</span>
</span><span id="__span-13-7"><a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a><span class="c1">#Writing output and error files</span>
</span><span id="__span-13-8"><a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a><span class="c1">#SBATCH --output=output%J.out</span>
</span><span id="__span-13-9"><a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a><span class="c1">#SBATCH --error=error%J.error</span>
</span><span id="__span-13-10"><a id="__codelineno-13-10" name="__codelineno-13-10" href="#__codelineno-13-10"></a>
</span><span id="__span-13-11"><a id="__codelineno-13-11" name="__codelineno-13-11" href="#__codelineno-13-11"></a>ml<span class="w"> </span>purge<span class="w"> </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-13-12"><a id="__codelineno-13-12" name="__codelineno-13-12" href="#__codelineno-13-12"></a><span class="c1"># Reloading a module that got removed with purge</span>
</span><span id="__span-13-13"><a id="__codelineno-13-13" name="__codelineno-13-13" href="#__codelineno-13-13"></a>ml<span class="w"> </span>Java/17
</span><span id="__span-13-14"><a id="__codelineno-13-14" name="__codelineno-13-14" href="#__codelineno-13-14"></a>ml<span class="w"> </span>R/4.4.2-gfbf-2024a<span class="w"> </span>R-bundle-CRAN/2024.11-foss-2024a<span class="w"> </span>R-bundle-Bioconductor/3.20-foss-2024a-R-4.4.2
</span><span id="__span-13-15"><a id="__codelineno-13-15" name="__codelineno-13-15" href="#__codelineno-13-15"></a>R<span class="w"> </span>--no-save<span class="w"> </span>--no-restore<span class="w"> </span>-f<span class="w"> </span>MY-R-GPU-SCRIPT.R
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="ch">#!/bin/bash</span>
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a><span class="c1">#SBATCH -A hpc2n2025-151 # Change to your own project ID</span>
</span><span id="__span-14-3"><a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a><span class="c1">#Asking for runtime: hours, minutes, seconds. At most 1 week</span>
</span><span id="__span-14-4"><a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a><span class="c1">#SBATCH -t HHH:MM:SS</span>
</span><span id="__span-14-5"><a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a><span class="c1">#Ask for GPU resources. You pick type as one of the ones shown above</span>
</span><span id="__span-14-6"><a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a><span class="c1">#x is how many cards you want, at most as many as shown above</span>
</span><span id="__span-14-7"><a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a><span class="c1">#SBATCH --gpus:x</span>
</span><span id="__span-14-8"><a id="__codelineno-14-8" name="__codelineno-14-8" href="#__codelineno-14-8"></a><span class="c1">#SBATCH -C type</span>
</span><span id="__span-14-9"><a id="__codelineno-14-9" name="__codelineno-14-9" href="#__codelineno-14-9"></a><span class="c1">#Writing output and error files</span>
</span><span id="__span-14-10"><a id="__codelineno-14-10" name="__codelineno-14-10" href="#__codelineno-14-10"></a><span class="c1">#SBATCH --output=output%J.out</span>
</span><span id="__span-14-11"><a id="__codelineno-14-11" name="__codelineno-14-11" href="#__codelineno-14-11"></a><span class="c1">#SBATCH --error=error%J.error</span>
</span><span id="__span-14-12"><a id="__codelineno-14-12" name="__codelineno-14-12" href="#__codelineno-14-12"></a>
</span><span id="__span-14-13"><a id="__codelineno-14-13" name="__codelineno-14-13" href="#__codelineno-14-13"></a>ml<span class="w"> </span>purge<span class="w"> </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-14-14"><a id="__codelineno-14-14" name="__codelineno-14-14" href="#__codelineno-14-14"></a><span class="c1">#R version 4.4.1</span>
</span><span id="__span-14-15"><a id="__codelineno-14-15" name="__codelineno-14-15" href="#__codelineno-14-15"></a>ml<span class="w"> </span>GCC/13.2.0<span class="w"> </span>R/4.4.1<span class="w"> </span>OpenMPI/4.1.6<span class="w"> </span>R-bundle-CRAN/2024.06
</span><span id="__span-14-16"><a id="__codelineno-14-16" name="__codelineno-14-16" href="#__codelineno-14-16"></a>ml<span class="w"> </span>CUDA/12.6.0
</span><span id="__span-14-17"><a id="__codelineno-14-17" name="__codelineno-14-17" href="#__codelineno-14-17"></a>
</span><span id="__span-14-18"><a id="__codelineno-14-18" name="__codelineno-14-18" href="#__codelineno-14-18"></a>R<span class="w"> </span>--no-save<span class="w"> </span>--no-restore<span class="w"> </span>-f<span class="w"> </span>MY-R-GPU-SCRIPT.R
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="ch">#!/bin/bash</span>
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="c1"># Remember to change this to your own project ID after the course!</span>
</span><span id="__span-15-3"><a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a><span class="c1">#SBATCH -A lu2025-2-94</span>
</span><span id="__span-15-4"><a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a><span class="c1"># Asking for runtime: hours, minutes, seconds. At most 1 week</span>
</span><span id="__span-15-5"><a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a><span class="c1">#SBATCH --time=HHH:MM:SS</span>
</span><span id="__span-15-6"><a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a><span class="c1"># Ask for GPU resources - x is how many cards, 1 or 2</span>
</span><span id="__span-15-7"><a id="__codelineno-15-7" name="__codelineno-15-7" href="#__codelineno-15-7"></a><span class="c1">#SBATCH -p gpua100</span>
</span><span id="__span-15-8"><a id="__codelineno-15-8" name="__codelineno-15-8" href="#__codelineno-15-8"></a><span class="c1">#SBATCH --gres=gpu:x</span>
</span><span id="__span-15-9"><a id="__codelineno-15-9" name="__codelineno-15-9" href="#__codelineno-15-9"></a>
</span><span id="__span-15-10"><a id="__codelineno-15-10" name="__codelineno-15-10" href="#__codelineno-15-10"></a><span class="c1"># Remove any loaded modules and load the ones we need</span>
</span><span id="__span-15-11"><a id="__codelineno-15-11" name="__codelineno-15-11" href="#__codelineno-15-11"></a>module<span class="w"> </span>purge<span class="w">  </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-15-12"><a id="__codelineno-15-12" name="__codelineno-15-12" href="#__codelineno-15-12"></a>module<span class="w"> </span>load<span class="w"> </span>GCC/11.3.0<span class="w">  </span>OpenMPI/4.1.4<span class="w"> </span>R/4.2.1<span class="w"> </span>CUDA/12.1.1
</span><span id="__span-15-13"><a id="__codelineno-15-13" name="__codelineno-15-13" href="#__codelineno-15-13"></a>
</span><span id="__span-15-14"><a id="__codelineno-15-14" name="__codelineno-15-14" href="#__codelineno-15-14"></a>R<span class="w"> </span>--no-save<span class="w"> </span>--no-restore<span class="w"> </span>-f<span class="w"> </span>MY-R-GPU-SCRIPT.R
</span></code></pre></div>
</div>
</div>
</div>
<h3 id="matlab">MATLAB<a class="headerlink" href="#matlab" title="Anchor link to this section for reference">&para;</a></h3>
<p>Here we cover how to use GPUs with MATLAB</p>
<ul>
<li>Inside MATLAB</li>
<li>In a batch script</li>
</ul>
<p>In order to use GPUs, you have to ask for them.</p>
<h4 id="inside-matlab">Inside MATLAB<a class="headerlink" href="#inside-matlab" title="Anchor link to this section for reference">&para;</a></h4>
<p>In order to use GPUs from inside MATLAB, you must add them as additional properties to your profile.</p>
<p>This is done the same whether you use MATLAB on the command line or inside the GUI. If you work inside the GUI it is also possible to set these GPU values in the Cluster Profile Manager. </p>
<p>Remember, after it is saved to your profile it will use GPUs again next time you submit a job, even if you don&rsquo;t want GPUs there. To reset this, do:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>c.AdditionalProperties.GpuCard<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="p">;</span>
</span><span id="__span-16-2"><a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>c.AdditionalProperties.GpusPerNode<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="p">;</span>
</span></code></pre></div>
<p>This is how you add GPUs to use in batch jobs submitted from inside MATLAB:</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Ask for a GPU and enough time to do what you need.</p>
</div>
<div class="tabbed-set tabbed-alternate" data-tabs="3:6"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><input id="__tabbed_3_2" name="__tabbed_3" type="radio" /><input id="__tabbed_3_3" name="__tabbed_3" type="radio" /><input id="__tabbed_3_4" name="__tabbed_3" type="radio" /><input id="__tabbed_3_5" name="__tabbed_3" type="radio" /><input id="__tabbed_3_6" name="__tabbed_3" type="radio" /><div class="tabbed-labels"><label for="__tabbed_3_1">UPPMAX</label><label for="__tabbed_3_2">HPC2N</label><label for="__tabbed_3_3">LUNARC</label><label for="__tabbed_3_4">NSC</label><label for="__tabbed_3_5">PDC</label><label for="__tabbed_3_6">C3SE</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>interactive<span class="w"> </span>-A<span class="w"> </span>uppmax2025-2-360<span class="w"> </span>-p<span class="w"> </span>gpu<span class="w"> </span>--gpus:l40s:1<span class="w"> </span>-t<span class="w"> </span><span class="m">2</span>:00:00
</span></code></pre></div>
<p>Load MATLAB</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a>ml<span class="w"> </span>MATLAB/2024a
</span></code></pre></div>
<p>Then run MATLAB either as GUI&hellip;</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>matlab<span class="w"> </span>-singleCompThread
</span></code></pre></div>
<p>&hellip;Or on the terminal</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a>matlab<span class="w"> </span>-singleCompThread<span class="w"> </span>-nodisplay<span class="w"> </span>-nosplash<span class="w"> </span>-nodesktop
</span></code></pre></div>
<p>Finally, inside MATLAB, add this to your profile (remember the <code>c=parcluster;</code> after you start MATLAB again, to get a handle):</p>
<div class="language-matlab highlight"><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">GpusPerNode</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a><span class="n">c</span><span class="p">.</span><span class="n">saveProfile</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p>Load and start MATLAB, then do (remember the <code>c=parcluster;</code> after you start MATLAB again, to get a handle)</p>
<div class="language-matlab highlight"><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">GpuCard</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&#39;card-type&#39;</span><span class="p">;</span>
</span><span id="__span-22-2"><a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">GpusPerNode</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&#39;#gpus&#39;</span><span class="p">;</span>
</span><span id="__span-22-3"><a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a><span class="n">c</span><span class="p">.</span><span class="n">saveProfile</span>
</span></code></pre></div>
<p>where <code>card-type</code> is one of <code>v100</code>, <code>a40</code>, <code>a6000</code>, <code>l40s</code>, <code>a100</code>, <code>h100</code>, or <code>mi100</code>, and <code>#gpus</code> depends on the card-type:</p>
<ul>
<li>V100 (2 cards/node)</li>
<li>A40 (8 cards/node)</li>
<li>A6000 (2 cards/node)</li>
<li>L40s (2 or 6 cards/node)</li>
<li>A100 (2 cards/node)</li>
<li>H100 (4 cards/node)</li>
<li>MI100 (2 cards/node)</li>
</ul>
</div>
<div class="tabbed-block">
<p>Load and start MATLAB, then do (remember the <code>c=parcluster;</code> after you start MATLAB again, to get a handle)</p>
<div class="language-matlab highlight"><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">GpusPerNode</span><span class="w"> </span><span class="p">=</span><span class="w"> </span>#<span class="n">GPUs</span><span class="p">;</span>
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a><span class="n">c</span><span class="p">.</span><span class="n">saveProfile</span>
</span></code></pre></div>
<p>where <code>#GPUs</code> is 1 or 2.</p>
</div>
<div class="tabbed-block">
<p>Load and start MATLAB, then do (remember the <code>c=parcluster;</code> after you start MATLAB again, to get a handle)</p>
<div class="language-matlab highlight"><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">GPUsPerNode</span><span class="w"> </span><span class="p">=</span><span class="w"> </span>#<span class="n">GPUs</span><span class="p">;</span>
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a><span class="n">c</span><span class="p">.</span><span class="n">saveProfile</span>
</span></code></pre></div>
<p>where <code>#GPUs</code> is 1 or 2.</p>
</div>
<div class="tabbed-block">
<p>Remember, here you cannot set <code>AdditionalProperties</code>. Instead, you do the following: </p>
<ol>
<li>Start an interactive session on the GPU partition: <code>salloc -N 1 --ntasks-per-node=1 --t 1:00:00 -A naiss2025-22-262 -p gpu</code></li>
<li>Load MATLAB: <code>module load PDCOLD/23.12 matlab/r2024a-ps</code></li>
<li>Start MATLAB: <code>matlab -nodisplay -nodesktop -nosplash</code></li>
</ol>
<p>You are now ready to run your GPU MATLAB scripts.</p>
</div>
<div class="tabbed-block">
<p>Remember, here you cannot set <code>AdditionalProperties</code>. Instead, you do the following: </p>
<ol>
<li>Start am interactive sesson asking for a GPU: <code>srun --account=naiss2025-22-934 --gpus-per-node=T4:1 --time=01:00:00 --pty /bin/bash</code>  </li>
<li>Load MATLAB: <code>module load MATLAB/2024b</code></li>
<li>Start MATLAB: <code>matlab -singleCompThread -nodisplay -nosplash -nodesktop</code></li>
</ol>
</div>
</div>
</div>
<div class="admonition example">
<p class="admonition-title"><strong>Challenge 5.</strong> Add/remove GPUs in your cluster profile</p>
<p>Try to add GPUs to your cluster profile and save it. Run <code>c.AdditionalProperties</code> to see what was added. Then do <code>c.AdditionalProperties.GpusPerNode = '';</code> to remove it. See that it was removed.</p>
</div>
<h4 id="matlab-with-gpus-in-batch-scripts">Matlab with GPUs in batch scripts<a class="headerlink" href="#matlab-with-gpus-in-batch-scripts" title="Anchor link to this section for reference">&para;</a></h4>
<p>How to request a GPU node varies somewhat between clusters. Refer to the following templates:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="4:6"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><input id="__tabbed_4_2" name="__tabbed_4" type="radio" /><input id="__tabbed_4_3" name="__tabbed_4" type="radio" /><input id="__tabbed_4_4" name="__tabbed_4" type="radio" /><input id="__tabbed_4_5" name="__tabbed_4" type="radio" /><input id="__tabbed_4_6" name="__tabbed_4" type="radio" /><div class="tabbed-labels"><label for="__tabbed_4_1">UPPMAX</label><label for="__tabbed_4_2">HPC2N</label><label for="__tabbed_4_3">LUNARC</label><label for="__tabbed_4_4">NSC</label><label for="__tabbed_4_5">PDC</label><label for="__tabbed_4_6">C3SE</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-25-1"><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="ch">#!/bin/bash</span>
</span><span id="__span-25-2"><a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a><span class="c1"># Change to your actual project number</span>
</span><span id="__span-25-3"><a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a><span class="c1">#SBATCH -A naiss2025-22-360</span>
</span><span id="__span-25-4"><a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a><span class="c1">#SBATCH -p gpu</span>
</span><span id="__span-25-5"><a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a><span class="c1">#SBATCH --gpus:l40s:1</span>
</span><span id="__span-25-6"><a id="__codelineno-25-6" name="__codelineno-25-6" href="#__codelineno-25-6"></a><span class="c1"># Asking for 30 min (change as you want)</span>
</span><span id="__span-25-7"><a id="__codelineno-25-7" name="__codelineno-25-7" href="#__codelineno-25-7"></a><span class="c1">#SBATCH -t 00:30:00</span>
</span><span id="__span-25-8"><a id="__codelineno-25-8" name="__codelineno-25-8" href="#__codelineno-25-8"></a><span class="c1">#SBATCH --error=matlab_%J.err</span>
</span><span id="__span-25-9"><a id="__codelineno-25-9" name="__codelineno-25-9" href="#__codelineno-25-9"></a><span class="c1">#SBATCH --output=matlab_%J.out</span>
</span><span id="__span-25-10"><a id="__codelineno-25-10" name="__codelineno-25-10" href="#__codelineno-25-10"></a>
</span><span id="__span-25-11"><a id="__codelineno-25-11" name="__codelineno-25-11" href="#__codelineno-25-11"></a><span class="c1"># Change depending on resource and MATLAB version</span>
</span><span id="__span-25-12"><a id="__codelineno-25-12" name="__codelineno-25-12" href="#__codelineno-25-12"></a><span class="c1"># to find out available versions: module spider MATLAB</span>
</span><span id="__span-25-13"><a id="__codelineno-25-13" name="__codelineno-25-13" href="#__codelineno-25-13"></a>module<span class="w"> </span>add<span class="w"> </span>MATLAB/2024a
</span><span id="__span-25-14"><a id="__codelineno-25-14" name="__codelineno-25-14" href="#__codelineno-25-14"></a>
</span><span id="__span-25-15"><a id="__codelineno-25-15" name="__codelineno-25-15" href="#__codelineno-25-15"></a><span class="c1"># Executing a GPU matlab program</span>
</span><span id="__span-25-16"><a id="__codelineno-25-16" name="__codelineno-25-16" href="#__codelineno-25-16"></a>matlab<span class="w"> </span>-nodisplay<span class="w"> </span>-nosplash<span class="w"> </span>-r<span class="w"> </span><span class="s2">&quot;gpu-matlab-script.m&quot;</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-26-1"><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="ch">#!/bin/bash</span>
</span><span id="__span-26-2"><a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a><span class="c1"># Change to your actual project number</span>
</span><span id="__span-26-3"><a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a><span class="c1">#SBATCH -A hpc2n2025-151</span>
</span><span id="__span-26-4"><a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a><span class="c1">#SBATCH -n 1</span>
</span><span id="__span-26-5"><a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a><span class="c1">#SBATCH --gpus=&lt;#gpus&gt;</span>
</span><span id="__span-26-6"><a id="__codelineno-26-6" name="__codelineno-26-6" href="#__codelineno-26-6"></a><span class="c1">#SBATCH -C &lt;gpu-type&gt;</span>
</span><span id="__span-26-7"><a id="__codelineno-26-7" name="__codelineno-26-7" href="#__codelineno-26-7"></a><span class="c1"># Asking for 30 min (change as you want)</span>
</span><span id="__span-26-8"><a id="__codelineno-26-8" name="__codelineno-26-8" href="#__codelineno-26-8"></a><span class="c1">#SBATCH -t 00:30:00</span>
</span><span id="__span-26-9"><a id="__codelineno-26-9" name="__codelineno-26-9" href="#__codelineno-26-9"></a><span class="c1">#SBATCH --error=matlab_%J.err</span>
</span><span id="__span-26-10"><a id="__codelineno-26-10" name="__codelineno-26-10" href="#__codelineno-26-10"></a><span class="c1">#SBATCH --output=matlab_%J.out</span>
</span><span id="__span-26-11"><a id="__codelineno-26-11" name="__codelineno-26-11" href="#__codelineno-26-11"></a>
</span><span id="__span-26-12"><a id="__codelineno-26-12" name="__codelineno-26-12" href="#__codelineno-26-12"></a><span class="c1"># Clean the environment</span>
</span><span id="__span-26-13"><a id="__codelineno-26-13" name="__codelineno-26-13" href="#__codelineno-26-13"></a>module<span class="w"> </span>purge<span class="w"> </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-26-14"><a id="__codelineno-26-14" name="__codelineno-26-14" href="#__codelineno-26-14"></a>
</span><span id="__span-26-15"><a id="__codelineno-26-15" name="__codelineno-26-15" href="#__codelineno-26-15"></a><span class="c1"># Change depending on resource and MATLAB version</span>
</span><span id="__span-26-16"><a id="__codelineno-26-16" name="__codelineno-26-16" href="#__codelineno-26-16"></a><span class="c1"># to find out available versions: module spider matlab</span>
</span><span id="__span-26-17"><a id="__codelineno-26-17" name="__codelineno-26-17" href="#__codelineno-26-17"></a>module<span class="w"> </span>load<span class="w"> </span>MATLAB/2023a.Update4
</span><span id="__span-26-18"><a id="__codelineno-26-18" name="__codelineno-26-18" href="#__codelineno-26-18"></a>
</span><span id="__span-26-19"><a id="__codelineno-26-19" name="__codelineno-26-19" href="#__codelineno-26-19"></a><span class="c1"># Executing a GPU matlab program</span>
</span><span id="__span-26-20"><a id="__codelineno-26-20" name="__codelineno-26-20" href="#__codelineno-26-20"></a>matlab<span class="w"> </span>-nodisplay<span class="w"> </span>-nosplash<span class="w"> </span>-r<span class="w"> </span><span class="s2">&quot;gpu-matlab-script.m&quot;</span>
</span></code></pre></div>
<p>where <code>card-type</code> is one of <code>v100</code>, <code>a40</code>, <code>a6000</code>, <code>l40s</code>, <code>a100</code>, <code>h100</code>, or <code>mi100</code>, and <code>#gpus</code> depends on the card-type:</p>
<ul>
<li>V100 (2 cards/node)</li>
<li>A40 (8 cards/node)</li>
<li>A6000 (2 cards/node)</li>
<li>L40s (2 or 6 cards/node)</li>
<li>A100 (2 cards/node)</li>
<li>H100 (4 cards/node)</li>
<li>MI100 (2 cards/node)</li>
</ul>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-27-1"><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a><span class="ch">#!/bin/bash</span>
</span><span id="__span-27-2"><a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a><span class="c1"># Change to your actual project number</span>
</span><span id="__span-27-3"><a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a><span class="c1">#SBATCH -A lu2025-7-94</span>
</span><span id="__span-27-4"><a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a><span class="c1">#SBATCH -n 1</span>
</span><span id="__span-27-5"><a id="__codelineno-27-5" name="__codelineno-27-5" href="#__codelineno-27-5"></a><span class="c1">#SBATCH -p gpua100</span>
</span><span id="__span-27-6"><a id="__codelineno-27-6" name="__codelineno-27-6" href="#__codelineno-27-6"></a><span class="c1"># The number of GPUs.#gpus, can be 1 or 2</span>
</span><span id="__span-27-7"><a id="__codelineno-27-7" name="__codelineno-27-7" href="#__codelineno-27-7"></a><span class="c1">#SBATCH --gpus=&lt;#gpus&gt;</span>
</span><span id="__span-27-8"><a id="__codelineno-27-8" name="__codelineno-27-8" href="#__codelineno-27-8"></a>
</span><span id="__span-27-9"><a id="__codelineno-27-9" name="__codelineno-27-9" href="#__codelineno-27-9"></a><span class="c1"># Asking for 30 min (change as you want)</span>
</span><span id="__span-27-10"><a id="__codelineno-27-10" name="__codelineno-27-10" href="#__codelineno-27-10"></a><span class="c1">#SBATCH -t 00:30:00</span>
</span><span id="__span-27-11"><a id="__codelineno-27-11" name="__codelineno-27-11" href="#__codelineno-27-11"></a><span class="c1">#SBATCH --error=matlab_%J.err</span>
</span><span id="__span-27-12"><a id="__codelineno-27-12" name="__codelineno-27-12" href="#__codelineno-27-12"></a><span class="c1">#SBATCH --output=matlab_%J.out</span>
</span><span id="__span-27-13"><a id="__codelineno-27-13" name="__codelineno-27-13" href="#__codelineno-27-13"></a>
</span><span id="__span-27-14"><a id="__codelineno-27-14" name="__codelineno-27-14" href="#__codelineno-27-14"></a><span class="c1"># Clean the environment</span>
</span><span id="__span-27-15"><a id="__codelineno-27-15" name="__codelineno-27-15" href="#__codelineno-27-15"></a>module<span class="w"> </span>purge<span class="w"> </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-27-16"><a id="__codelineno-27-16" name="__codelineno-27-16" href="#__codelineno-27-16"></a>
</span><span id="__span-27-17"><a id="__codelineno-27-17" name="__codelineno-27-17" href="#__codelineno-27-17"></a><span class="c1"># Change depending on resource and MATLAB version</span>
</span><span id="__span-27-18"><a id="__codelineno-27-18" name="__codelineno-27-18" href="#__codelineno-27-18"></a><span class="c1"># to find out available versions: module spider matlab</span>
</span><span id="__span-27-19"><a id="__codelineno-27-19" name="__codelineno-27-19" href="#__codelineno-27-19"></a>module<span class="w"> </span>load<span class="w"> </span>matlab/2023b
</span><span id="__span-27-20"><a id="__codelineno-27-20" name="__codelineno-27-20" href="#__codelineno-27-20"></a>
</span><span id="__span-27-21"><a id="__codelineno-27-21" name="__codelineno-27-21" href="#__codelineno-27-21"></a><span class="c1"># Executing a GPU matlab program</span>
</span><span id="__span-27-22"><a id="__codelineno-27-22" name="__codelineno-27-22" href="#__codelineno-27-22"></a>matlab<span class="w"> </span>-nodisplay<span class="w"> </span>-nosplash<span class="w"> </span>-r<span class="w"> </span><span class="s2">&quot;gpu-matlab-script.m&quot;</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-28-1"><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a><span class="ch">#!/bin/bash</span>
</span><span id="__span-28-2"><a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a><span class="c1"># Change to your actual project number</span>
</span><span id="__span-28-3"><a id="__codelineno-28-3" name="__codelineno-28-3" href="#__codelineno-28-3"></a><span class="c1">#SBATCH -A naiss2025-22-934</span>
</span><span id="__span-28-4"><a id="__codelineno-28-4" name="__codelineno-28-4" href="#__codelineno-28-4"></a><span class="c1">#SBATCH --ntasks=1</span>
</span><span id="__span-28-5"><a id="__codelineno-28-5" name="__codelineno-28-5" href="#__codelineno-28-5"></a><span class="c1">#SBATCH --cpus-per-task=1</span>
</span><span id="__span-28-6"><a id="__codelineno-28-6" name="__codelineno-28-6" href="#__codelineno-28-6"></a><span class="c1">#SBATCH --ntasks-per-core=1</span>
</span><span id="__span-28-7"><a id="__codelineno-28-7" name="__codelineno-28-7" href="#__codelineno-28-7"></a><span class="c1"># The number of GPUs.#gpus, can be 1 or 2</span>
</span><span id="__span-28-8"><a id="__codelineno-28-8" name="__codelineno-28-8" href="#__codelineno-28-8"></a><span class="c1">#SBATCH --gpus-per-task=1</span>
</span><span id="__span-28-9"><a id="__codelineno-28-9" name="__codelineno-28-9" href="#__codelineno-28-9"></a>
</span><span id="__span-28-10"><a id="__codelineno-28-10" name="__codelineno-28-10" href="#__codelineno-28-10"></a><span class="c1"># Asking for 30 min (change as you want)</span>
</span><span id="__span-28-11"><a id="__codelineno-28-11" name="__codelineno-28-11" href="#__codelineno-28-11"></a><span class="c1">#SBATCH -t 00:30:00</span>
</span><span id="__span-28-12"><a id="__codelineno-28-12" name="__codelineno-28-12" href="#__codelineno-28-12"></a><span class="c1">#SBATCH --error=matlab_%J.err</span>
</span><span id="__span-28-13"><a id="__codelineno-28-13" name="__codelineno-28-13" href="#__codelineno-28-13"></a><span class="c1">#SBATCH --output=matlab_%J.out</span>
</span><span id="__span-28-14"><a id="__codelineno-28-14" name="__codelineno-28-14" href="#__codelineno-28-14"></a>
</span><span id="__span-28-15"><a id="__codelineno-28-15" name="__codelineno-28-15" href="#__codelineno-28-15"></a><span class="c1"># Clean the environment</span>
</span><span id="__span-28-16"><a id="__codelineno-28-16" name="__codelineno-28-16" href="#__codelineno-28-16"></a>module<span class="w"> </span>purge<span class="w"> </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-28-17"><a id="__codelineno-28-17" name="__codelineno-28-17" href="#__codelineno-28-17"></a>
</span><span id="__span-28-18"><a id="__codelineno-28-18" name="__codelineno-28-18" href="#__codelineno-28-18"></a><span class="c1"># Change depending on resource and MATLAB version</span>
</span><span id="__span-28-19"><a id="__codelineno-28-19" name="__codelineno-28-19" href="#__codelineno-28-19"></a><span class="c1"># to find out available versions: module spider matlab</span>
</span><span id="__span-28-20"><a id="__codelineno-28-20" name="__codelineno-28-20" href="#__codelineno-28-20"></a>module<span class="w"> </span>load<span class="w"> </span>MATLAB/2024a-hpc1-bdist
</span><span id="__span-28-21"><a id="__codelineno-28-21" name="__codelineno-28-21" href="#__codelineno-28-21"></a>
</span><span id="__span-28-22"><a id="__codelineno-28-22" name="__codelineno-28-22" href="#__codelineno-28-22"></a><span class="c1"># Executing a GPU matlab program</span>
</span><span id="__span-28-23"><a id="__codelineno-28-23" name="__codelineno-28-23" href="#__codelineno-28-23"></a>matlab<span class="w"> </span>-singleCompThread<span class="w"> </span>-nodisplay<span class="w"> </span>-nosplash<span class="w"> </span>-r<span class="w"> </span><span class="s2">&quot;gpu-matlab-script.m&quot;</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-29-1"><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a><span class="ch">#!/bin/bash</span>
</span><span id="__span-29-2"><a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a><span class="c1"># Change to your actual project number</span>
</span><span id="__span-29-3"><a id="__codelineno-29-3" name="__codelineno-29-3" href="#__codelineno-29-3"></a><span class="c1">#SBATCH -A naiss2025-22-934</span>
</span><span id="__span-29-4"><a id="__codelineno-29-4" name="__codelineno-29-4" href="#__codelineno-29-4"></a><span class="c1">#SBATCH --ntasks-per-node=1</span>
</span><span id="__span-29-5"><a id="__codelineno-29-5" name="__codelineno-29-5" href="#__codelineno-29-5"></a><span class="c1">#SBATCH -N 1</span>
</span><span id="__span-29-6"><a id="__codelineno-29-6" name="__codelineno-29-6" href="#__codelineno-29-6"></a><span class="c1"># Ask for GPUs</span>
</span><span id="__span-29-7"><a id="__codelineno-29-7" name="__codelineno-29-7" href="#__codelineno-29-7"></a><span class="c1">#SBATCH -p gpu</span>
</span><span id="__span-29-8"><a id="__codelineno-29-8" name="__codelineno-29-8" href="#__codelineno-29-8"></a>
</span><span id="__span-29-9"><a id="__codelineno-29-9" name="__codelineno-29-9" href="#__codelineno-29-9"></a><span class="c1"># Asking for 30 min (change as you want)</span>
</span><span id="__span-29-10"><a id="__codelineno-29-10" name="__codelineno-29-10" href="#__codelineno-29-10"></a><span class="c1">#SBATCH -t 00:30:00</span>
</span><span id="__span-29-11"><a id="__codelineno-29-11" name="__codelineno-29-11" href="#__codelineno-29-11"></a><span class="c1">#SBATCH --error=matlab_%J.err</span>
</span><span id="__span-29-12"><a id="__codelineno-29-12" name="__codelineno-29-12" href="#__codelineno-29-12"></a><span class="c1">#SBATCH --output=matlab_%J.out</span>
</span><span id="__span-29-13"><a id="__codelineno-29-13" name="__codelineno-29-13" href="#__codelineno-29-13"></a>
</span><span id="__span-29-14"><a id="__codelineno-29-14" name="__codelineno-29-14" href="#__codelineno-29-14"></a><span class="c1"># Clean the environment</span>
</span><span id="__span-29-15"><a id="__codelineno-29-15" name="__codelineno-29-15" href="#__codelineno-29-15"></a>module<span class="w"> </span>purge<span class="w"> </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-29-16"><a id="__codelineno-29-16" name="__codelineno-29-16" href="#__codelineno-29-16"></a>
</span><span id="__span-29-17"><a id="__codelineno-29-17" name="__codelineno-29-17" href="#__codelineno-29-17"></a><span class="c1"># Change depending on resource and MATLAB version</span>
</span><span id="__span-29-18"><a id="__codelineno-29-18" name="__codelineno-29-18" href="#__codelineno-29-18"></a><span class="c1"># to find out available versions: module spider matlab</span>
</span><span id="__span-29-19"><a id="__codelineno-29-19" name="__codelineno-29-19" href="#__codelineno-29-19"></a>module<span class="w"> </span>load<span class="w"> </span>PDC/24.11<span class="w"> </span>matlab/r2024b<span class="w"> </span>rocm/5.7.0
</span><span id="__span-29-20"><a id="__codelineno-29-20" name="__codelineno-29-20" href="#__codelineno-29-20"></a>
</span><span id="__span-29-21"><a id="__codelineno-29-21" name="__codelineno-29-21" href="#__codelineno-29-21"></a><span class="c1"># Executing a GPU matlab program</span>
</span><span id="__span-29-22"><a id="__codelineno-29-22" name="__codelineno-29-22" href="#__codelineno-29-22"></a>matlab<span class="w"> </span>-singleCompThread<span class="w"> </span>-nodisplay<span class="w"> </span>-nosplash<span class="w"> </span>-r<span class="w"> </span><span class="s2">&quot;gpu-matlab-script.m&quot;</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-30-1"><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a><span class="ch">#!/bin/bash</span>
</span><span id="__span-30-2"><a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a><span class="c1"># Remember to change this to your own project ID after the course!</span>
</span><span id="__span-30-3"><a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a><span class="c1">#SBATCH -A NAISS2025-22-934</span>
</span><span id="__span-30-4"><a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a><span class="c1">#SBATCH -t 00:30:00</span>
</span><span id="__span-30-5"><a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a><span class="c1">#SBATCH -p alvis</span>
</span><span id="__span-30-6"><a id="__codelineno-30-6" name="__codelineno-30-6" href="#__codelineno-30-6"></a><span class="c1">#You always need to ask for GPUs on Alvis! And you should not use it for anything but GPU jobs! </span>
</span><span id="__span-30-7"><a id="__codelineno-30-7" name="__codelineno-30-7" href="#__codelineno-30-7"></a><span class="c1">#SBATCH -N 1 --gpus-per-node=T4:1</span>
</span><span id="__span-30-8"><a id="__codelineno-30-8" name="__codelineno-30-8" href="#__codelineno-30-8"></a>
</span><span id="__span-30-9"><a id="__codelineno-30-9" name="__codelineno-30-9" href="#__codelineno-30-9"></a>ml<span class="w"> </span>purge<span class="w"> </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-30-10"><a id="__codelineno-30-10" name="__codelineno-30-10" href="#__codelineno-30-10"></a>module<span class="w"> </span>load<span class="w"> </span>MATLAB/2024b
</span><span id="__span-30-11"><a id="__codelineno-30-11" name="__codelineno-30-11" href="#__codelineno-30-11"></a>
</span><span id="__span-30-12"><a id="__codelineno-30-12" name="__codelineno-30-12" href="#__codelineno-30-12"></a>matlab<span class="w"> </span>-singleCompThread<span class="w"> </span>-nodisplay<span class="w"> </span>-nosplash<span class="w"> </span>-r<span class="w"> </span><span class="s2">&quot;gpu-matlab-script.m&quot;</span>
</span></code></pre></div>
</div>
</div>
</div>
<h3 id="julia">Julia<a class="headerlink" href="#julia" title="Anchor link to this section for reference">&para;</a></h3>
<p>In order to use the NVIDIA GPUs with Julia (UPPMAX, HPC2N, and LUNARC), you will need to load a CUDA toolkit module on the
cluster and install the <code>CUDA</code> package in Julia. </p>
<p>In the case of AMD GPUs for Julia (PDC and HPC2N), you will need to load a ROCM toolkit module on the
cluster and install the <code>AMDGPU</code> package in Julia as in the next sequence of commands.</p>
<div class="admonition important">
<p class="admonition-title">Prerequisites</p>
<div class="tabbed-set tabbed-alternate" data-tabs="5:5"><input checked="checked" id="__tabbed_5_1" name="__tabbed_5" type="radio" /><input id="__tabbed_5_2" name="__tabbed_5" type="radio" /><input id="__tabbed_5_3" name="__tabbed_5" type="radio" /><input id="__tabbed_5_4" name="__tabbed_5" type="radio" /><input id="__tabbed_5_5" name="__tabbed_5" type="radio" /><div class="tabbed-labels"><label for="__tabbed_5_1">UPPMAX</label><label for="__tabbed_5_2">HPC2N</label><label for="__tabbed_5_3">LUNARC</label><label for="__tabbed_5_4">PDC</label><label for="__tabbed_5_5">NSC</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<ul>
<li>This can only be done on Snowy or Bianca. </li>
<li>Then either create an interactive session or make a batch job</li>
<li>
<p>CUDA is installed at system level so they do not need to be loaded. </p>
</li>
<li>
<p>On snowy </p>
</li>
</ul>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-31-1"><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a>$<span class="w"> </span>interactive<span class="w"> </span>-A<span class="w"> </span>&lt;proj&gt;<span class="w"> </span>-n<span class="w"> </span><span class="m">1</span><span class="w"> </span>-M<span class="w"> </span>snowy<span class="w"> </span>--gres<span class="o">=</span>gpu:1<span class="w">  </span>-t<span class="w"> </span><span class="m">3</span>:00:00
</span><span id="__span-31-2"><a id="__codelineno-31-2" name="__codelineno-31-2" href="#__codelineno-31-2"></a>
</span><span id="__span-31-3"><a id="__codelineno-31-3" name="__codelineno-31-3" href="#__codelineno-31-3"></a>$<span class="w"> </span>ml<span class="w"> </span>Julia/1.8.5<span class="w">   </span><span class="c1"># Julia version</span>
</span><span id="__span-31-4"><a id="__codelineno-31-4" name="__codelineno-31-4" href="#__codelineno-31-4"></a>$<span class="w"> </span>julia
</span><span id="__span-31-5"><a id="__codelineno-31-5" name="__codelineno-31-5" href="#__codelineno-31-5"></a><span class="o">(</span>v1.8<span class="o">)</span><span class="w"> </span>pkg&gt;<span class="w"> </span>add<span class="w"> </span>CUDA<span class="w"> </span>
</span><span id="__span-31-6"><a id="__codelineno-31-6" name="__codelineno-31-6" href="#__codelineno-31-6"></a><span class="w">    </span>Updating<span class="w"> </span>registry<span class="w"> </span>at<span class="w"> </span><span class="sb">`</span>~/.julia/registries/General.toml<span class="sb">`</span>
</span><span id="__span-31-7"><a id="__codelineno-31-7" name="__codelineno-31-7" href="#__codelineno-31-7"></a><span class="w">    </span>Resolving<span class="w"> </span>package<span class="w"> </span>versions...
</span><span id="__span-31-8"><a id="__codelineno-31-8" name="__codelineno-31-8" href="#__codelineno-31-8"></a><span class="w">    </span>Installed<span class="w"> </span>CEnum<span class="w"> </span>─────────<span class="w"> </span>v0.4.2
</span><span id="__span-31-9"><a id="__codelineno-31-9" name="__codelineno-31-9" href="#__codelineno-31-9"></a><span class="w">    </span>...
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-32-1"><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a>$<span class="w"> </span>ml<span class="w"> </span>Julia/1.8.5-linux-x86_64<span class="w">   </span><span class="c1"># Julia version</span>
</span><span id="__span-32-2"><a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a>$<span class="w"> </span>ml<span class="w"> </span>CUDA/11.4.1<span class="w">                </span><span class="c1"># CUDA toolkit module</span>
</span><span id="__span-32-3"><a id="__codelineno-32-3" name="__codelineno-32-3" href="#__codelineno-32-3"></a>$<span class="w"> </span>julia
</span><span id="__span-32-4"><a id="__codelineno-32-4" name="__codelineno-32-4" href="#__codelineno-32-4"></a><span class="o">(</span>v1.8<span class="o">)</span><span class="w"> </span>pkg&gt;<span class="w"> </span>add<span class="w"> </span>CUDA<span class="w"> </span>
</span><span id="__span-32-5"><a id="__codelineno-32-5" name="__codelineno-32-5" href="#__codelineno-32-5"></a><span class="w">    </span>Updating<span class="w"> </span>registry<span class="w"> </span>at<span class="w"> </span><span class="sb">`</span>~/.julia/registries/General.toml<span class="sb">`</span>
</span><span id="__span-32-6"><a id="__codelineno-32-6" name="__codelineno-32-6" href="#__codelineno-32-6"></a><span class="w">    </span>Resolving<span class="w"> </span>package<span class="w"> </span>versions...
</span><span id="__span-32-7"><a id="__codelineno-32-7" name="__codelineno-32-7" href="#__codelineno-32-7"></a><span class="w">    </span>Installed<span class="w"> </span>CEnum<span class="w"> </span>─────────<span class="w"> </span>v0.4.2
</span><span id="__span-32-8"><a id="__codelineno-32-8" name="__codelineno-32-8" href="#__codelineno-32-8"></a><span class="w">    </span>...
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-33-1"><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a>$<span class="w"> </span>ml<span class="w"> </span>Julia/1.8.5-linux-x86_64<span class="w">   </span><span class="c1"># Julia version</span>
</span><span id="__span-33-2"><a id="__codelineno-33-2" name="__codelineno-33-2" href="#__codelineno-33-2"></a>$<span class="w"> </span>ml<span class="w"> </span>CUDA/11.4.1<span class="w">                </span><span class="c1"># CUDA toolkit module</span>
</span><span id="__span-33-3"><a id="__codelineno-33-3" name="__codelineno-33-3" href="#__codelineno-33-3"></a>$<span class="w"> </span>julia
</span><span id="__span-33-4"><a id="__codelineno-33-4" name="__codelineno-33-4" href="#__codelineno-33-4"></a><span class="o">(</span>v1.8<span class="o">)</span><span class="w"> </span>pkg&gt;<span class="w"> </span>add<span class="w"> </span>CUDA<span class="w"> </span>
</span><span id="__span-33-5"><a id="__codelineno-33-5" name="__codelineno-33-5" href="#__codelineno-33-5"></a><span class="w">    </span>Updating<span class="w"> </span>registry<span class="w"> </span>at<span class="w"> </span><span class="sb">`</span>~/.julia/registries/General.toml<span class="sb">`</span>
</span><span id="__span-33-6"><a id="__codelineno-33-6" name="__codelineno-33-6" href="#__codelineno-33-6"></a><span class="w">    </span>Resolving<span class="w"> </span>package<span class="w"> </span>versions...
</span><span id="__span-33-7"><a id="__codelineno-33-7" name="__codelineno-33-7" href="#__codelineno-33-7"></a><span class="w">    </span>Installed<span class="w"> </span>CEnum<span class="w"> </span>─────────<span class="w"> </span>v0.4.2
</span><span id="__span-33-8"><a id="__codelineno-33-8" name="__codelineno-33-8" href="#__codelineno-33-8"></a><span class="w">    </span>...
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-34-1"><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a>$<span class="w"> </span>ml<span class="w"> </span>PDC/23.12<span class="w"> </span>julia/1.10.2-cpeGNU-23.12<span class="w">   </span><span class="c1"># Julia version</span>
</span><span id="__span-34-2"><a id="__codelineno-34-2" name="__codelineno-34-2" href="#__codelineno-34-2"></a>$<span class="w"> </span>ml<span class="w"> </span>rocm/5.7.0<span class="w">  </span>craype-accel-amd-gfx90a<span class="w">   </span><span class="c1"># ROCM toolkit module</span>
</span><span id="__span-34-3"><a id="__codelineno-34-3" name="__codelineno-34-3" href="#__codelineno-34-3"></a>$<span class="w"> </span>julia
</span><span id="__span-34-4"><a id="__codelineno-34-4" name="__codelineno-34-4" href="#__codelineno-34-4"></a><span class="o">(</span>v1.10<span class="o">)</span><span class="w"> </span>pkg&gt;<span class="w"> </span>add<span class="w"> </span>AMDGPU<span class="w"> </span>
</span><span id="__span-34-5"><a id="__codelineno-34-5" name="__codelineno-34-5" href="#__codelineno-34-5"></a><span class="w">    </span>Updating<span class="w"> </span>registry<span class="w"> </span>at<span class="w"> </span><span class="sb">`</span>~/.julia/registries/General.toml<span class="sb">`</span>
</span><span id="__span-34-6"><a id="__codelineno-34-6" name="__codelineno-34-6" href="#__codelineno-34-6"></a><span class="w">    </span>Resolving<span class="w"> </span>package<span class="w"> </span>versions...
</span><span id="__span-34-7"><a id="__codelineno-34-7" name="__codelineno-34-7" href="#__codelineno-34-7"></a><span class="w">    </span>Installed<span class="w"> </span>CEnum<span class="w"> </span>─────────<span class="w"> </span>v0.4.2
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-35-1"><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a>$<span class="w"> </span>interactive<span class="w"> </span>-A<span class="w"> </span>&lt;proj&gt;<span class="w"> </span>-n<span class="w"> </span><span class="m">1</span><span class="w"> </span>-c<span class="w"> </span><span class="m">32</span><span class="w"> </span>--gpus-per-task<span class="o">=</span><span class="m">1</span><span class="w"> </span>-t<span class="w"> </span><span class="m">1</span>:00:00
</span><span id="__span-35-2"><a id="__codelineno-35-2" name="__codelineno-35-2" href="#__codelineno-35-2"></a>
</span><span id="__span-35-3"><a id="__codelineno-35-3" name="__codelineno-35-3" href="#__codelineno-35-3"></a>$<span class="w"> </span>ml<span class="w"> </span>buildenv-gcccuda/11.6.2-gcc9-hpc1<span class="w">  </span><span class="c1"># Load tool chain with CUDA</span>
</span><span id="__span-35-4"><a id="__codelineno-35-4" name="__codelineno-35-4" href="#__codelineno-35-4"></a>$<span class="w"> </span>ml<span class="w"> </span>julia/1.9.4-bdist<span class="w">                  </span><span class="c1"># Julia version</span>
</span><span id="__span-35-5"><a id="__codelineno-35-5" name="__codelineno-35-5" href="#__codelineno-35-5"></a>$<span class="w"> </span>julia
</span><span id="__span-35-6"><a id="__codelineno-35-6" name="__codelineno-35-6" href="#__codelineno-35-6"></a><span class="o">(</span>v1.9<span class="o">)</span><span class="w"> </span>pkg&gt;<span class="w"> </span>add<span class="w"> </span>LinearAlgebra
</span><span id="__span-35-7"><a id="__codelineno-35-7" name="__codelineno-35-7" href="#__codelineno-35-7"></a><span class="o">(</span>v1.9<span class="o">)</span><span class="w"> </span>pkg&gt;<span class="w"> </span>add<span class="w"> </span>CUDA<span class="w"> </span>
</span><span id="__span-35-8"><a id="__codelineno-35-8" name="__codelineno-35-8" href="#__codelineno-35-8"></a><span class="w">    </span>Updating<span class="w"> </span>registry<span class="w"> </span>at<span class="w"> </span><span class="sb">`</span>~/.julia/registries/General.toml<span class="sb">`</span>
</span><span id="__span-35-9"><a id="__codelineno-35-9" name="__codelineno-35-9" href="#__codelineno-35-9"></a><span class="w">    </span>Resolving<span class="w"> </span>package<span class="w"> </span>versions...
</span><span id="__span-35-10"><a id="__codelineno-35-10" name="__codelineno-35-10" href="#__codelineno-35-10"></a><span class="w">    </span>...
</span></code></pre></div>
</div>
</div>
</div>
</div>
<p>Once this initial setting is completed, you will be able to use the GPUs available on the
cluster. Here, there is a simple example for computing a matrix-matrix multiplication. As a 
reference point, we show the simulation on CPUs as well. You can call the batch script <code>job-gpu.sh</code>, 
for instance.</p>
<div class="admonition important">
<p class="admonition-title">Running on NVIDIA GPUs</p>
<div class="tabbed-set tabbed-alternate" data-tabs="6:5"><input checked="checked" id="__tabbed_6_1" name="__tabbed_6" type="radio" /><input id="__tabbed_6_2" name="__tabbed_6" type="radio" /><input id="__tabbed_6_3" name="__tabbed_6" type="radio" /><input id="__tabbed_6_4" name="__tabbed_6" type="radio" /><input id="__tabbed_6_5" name="__tabbed_6" type="radio" /><div class="tabbed-labels"><label for="__tabbed_6_1">UPPMAX</label><label for="__tabbed_6_2">HPC2N</label><label for="__tabbed_6_3">LUNARC</label><label for="__tabbed_6_4">NSC</label><label for="__tabbed_6_5">script-gpu.jl</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>Short GPU example for running on Snowy.         </p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-36-1"><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a><span class="ch">#!/bin/bash -l</span>
</span><span id="__span-36-2"><a id="__codelineno-36-2" name="__codelineno-36-2" href="#__codelineno-36-2"></a><span class="c1">#SBATCH -A naiss202t-uv-wxyz     # your project_ID  </span>
</span><span id="__span-36-3"><a id="__codelineno-36-3" name="__codelineno-36-3" href="#__codelineno-36-3"></a><span class="c1">#SBATCH -M snowy</span>
</span><span id="__span-36-4"><a id="__codelineno-36-4" name="__codelineno-36-4" href="#__codelineno-36-4"></a><span class="c1">#SBATCH -p node</span>
</span><span id="__span-36-5"><a id="__codelineno-36-5" name="__codelineno-36-5" href="#__codelineno-36-5"></a><span class="c1">#SBATCH --gres=gpu:1</span>
</span><span id="__span-36-6"><a id="__codelineno-36-6" name="__codelineno-36-6" href="#__codelineno-36-6"></a><span class="c1">#SBATCH -N 1</span>
</span><span id="__span-36-7"><a id="__codelineno-36-7" name="__codelineno-36-7" href="#__codelineno-36-7"></a><span class="c1">#SBATCH --job-name=job-gpu       # create a short name for your job</span>
</span><span id="__span-36-8"><a id="__codelineno-36-8" name="__codelineno-36-8" href="#__codelineno-36-8"></a><span class="c1">#SBATCH --time=00:15:00          # total run time limit (HH:MM:SS)</span>
</span><span id="__span-36-9"><a id="__codelineno-36-9" name="__codelineno-36-9" href="#__codelineno-36-9"></a><span class="c1">#SBATCH --qos=short              # if test run t&lt;15 min</span>
</span><span id="__span-36-10"><a id="__codelineno-36-10" name="__codelineno-36-10" href="#__codelineno-36-10"></a><span class="c1">#SBATCH --mail-type=begin        # send email when job begins</span>
</span><span id="__span-36-11"><a id="__codelineno-36-11" name="__codelineno-36-11" href="#__codelineno-36-11"></a><span class="c1">#SBATCH --mail-type=end          # send email when job ends</span>
</span><span id="__span-36-12"><a id="__codelineno-36-12" name="__codelineno-36-12" href="#__codelineno-36-12"></a>
</span><span id="__span-36-13"><a id="__codelineno-36-13" name="__codelineno-36-13" href="#__codelineno-36-13"></a>module<span class="w"> </span>load<span class="w"> </span>julia/1.8.5<span class="w">      </span><span class="c1"># system CUDA works as of today</span>
</span><span id="__span-36-14"><a id="__codelineno-36-14" name="__codelineno-36-14" href="#__codelineno-36-14"></a>julia<span class="w"> </span>script-gpu.jl
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-37-1"><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a><span class="ch">#!/bin/bash            </span>
</span><span id="__span-37-2"><a id="__codelineno-37-2" name="__codelineno-37-2" href="#__codelineno-37-2"></a><span class="c1">#SBATCH -A hpc2n202w-xyz     # your project_ID       </span>
</span><span id="__span-37-3"><a id="__codelineno-37-3" name="__codelineno-37-3" href="#__codelineno-37-3"></a><span class="c1">#SBATCH -J job-gpu           # name of the job         </span>
</span><span id="__span-37-4"><a id="__codelineno-37-4" name="__codelineno-37-4" href="#__codelineno-37-4"></a><span class="c1">#SBATCH -n 1                 # nr. tasks  </span>
</span><span id="__span-37-5"><a id="__codelineno-37-5" name="__codelineno-37-5" href="#__codelineno-37-5"></a><span class="c1">#SBATCH --time=00:03:00      # requested time</span>
</span><span id="__span-37-6"><a id="__codelineno-37-6" name="__codelineno-37-6" href="#__codelineno-37-6"></a><span class="c1">#SBATCH --error=job.%J.err   # error file</span>
</span><span id="__span-37-7"><a id="__codelineno-37-7" name="__codelineno-37-7" href="#__codelineno-37-7"></a><span class="c1">#SBATCH --output=job.%J.out  # output file  </span>
</span><span id="__span-37-8"><a id="__codelineno-37-8" name="__codelineno-37-8" href="#__codelineno-37-8"></a><span class="c1">#SBATCH --gres=gpu:v100:1     # 1 GPU v100 card</span>
</span><span id="__span-37-9"><a id="__codelineno-37-9" name="__codelineno-37-9" href="#__codelineno-37-9"></a>
</span><span id="__span-37-10"><a id="__codelineno-37-10" name="__codelineno-37-10" href="#__codelineno-37-10"></a>ml<span class="w"> </span>purge<span class="w">  </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-37-11"><a id="__codelineno-37-11" name="__codelineno-37-11" href="#__codelineno-37-11"></a>ml<span class="w"> </span>Julia/1.8.5-linux-x86_64
</span><span id="__span-37-12"><a id="__codelineno-37-12" name="__codelineno-37-12" href="#__codelineno-37-12"></a>ml<span class="w"> </span>CUDA/11.4.1
</span><span id="__span-37-13"><a id="__codelineno-37-13" name="__codelineno-37-13" href="#__codelineno-37-13"></a>
</span><span id="__span-37-14"><a id="__codelineno-37-14" name="__codelineno-37-14" href="#__codelineno-37-14"></a>julia<span class="w"> </span>script-gpu.jl
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-38-1"><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a><span class="ch">#!/bin/bash            </span>
</span><span id="__span-38-2"><a id="__codelineno-38-2" name="__codelineno-38-2" href="#__codelineno-38-2"></a><span class="c1">#SBATCH -A lu202w-x-yz       # your project_ID       </span>
</span><span id="__span-38-3"><a id="__codelineno-38-3" name="__codelineno-38-3" href="#__codelineno-38-3"></a><span class="c1">#SBATCH -J job-gpu           # name of the job         </span>
</span><span id="__span-38-4"><a id="__codelineno-38-4" name="__codelineno-38-4" href="#__codelineno-38-4"></a><span class="c1">#SBATCH -n 1                 # nr. tasks  </span>
</span><span id="__span-38-5"><a id="__codelineno-38-5" name="__codelineno-38-5" href="#__codelineno-38-5"></a><span class="c1">#SBATCH --time=00:03:00      # requested time</span>
</span><span id="__span-38-6"><a id="__codelineno-38-6" name="__codelineno-38-6" href="#__codelineno-38-6"></a><span class="c1">#SBATCH --error=job.%J.err   # error file</span>
</span><span id="__span-38-7"><a id="__codelineno-38-7" name="__codelineno-38-7" href="#__codelineno-38-7"></a><span class="c1">#SBATCH --output=job.%J.out  # output file</span>
</span><span id="__span-38-8"><a id="__codelineno-38-8" name="__codelineno-38-8" href="#__codelineno-38-8"></a><span class="c1">#Asking for one A100 GPU</span>
</span><span id="__span-38-9"><a id="__codelineno-38-9" name="__codelineno-38-9" href="#__codelineno-38-9"></a><span class="c1">#SBATCH -p gpua100</span>
</span><span id="__span-38-10"><a id="__codelineno-38-10" name="__codelineno-38-10" href="#__codelineno-38-10"></a><span class="c1">#SBATCH --gres=gpu:1              </span>
</span><span id="__span-38-11"><a id="__codelineno-38-11" name="__codelineno-38-11" href="#__codelineno-38-11"></a>
</span><span id="__span-38-12"><a id="__codelineno-38-12" name="__codelineno-38-12" href="#__codelineno-38-12"></a>ml<span class="w"> </span>purge<span class="w">  </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-38-13"><a id="__codelineno-38-13" name="__codelineno-38-13" href="#__codelineno-38-13"></a>ml<span class="w"> </span>Julia/1.8.5-linux-x86_64
</span><span id="__span-38-14"><a id="__codelineno-38-14" name="__codelineno-38-14" href="#__codelineno-38-14"></a>ml<span class="w"> </span>CUDA/11.4.1
</span><span id="__span-38-15"><a id="__codelineno-38-15" name="__codelineno-38-15" href="#__codelineno-38-15"></a>
</span><span id="__span-38-16"><a id="__codelineno-38-16" name="__codelineno-38-16" href="#__codelineno-38-16"></a>julia<span class="w"> </span>script-gpu.jl
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-39-1"><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a><span class="ch">#!/bin/bash            </span>
</span><span id="__span-39-2"><a id="__codelineno-39-2" name="__codelineno-39-2" href="#__codelineno-39-2"></a><span class="c1">#SBATCH -A naiss202t-uv-wxyz # your project_ID </span>
</span><span id="__span-39-3"><a id="__codelineno-39-3" name="__codelineno-39-3" href="#__codelineno-39-3"></a><span class="c1">#SBATCH -J job-gpu           # name of the job         </span>
</span><span id="__span-39-4"><a id="__codelineno-39-4" name="__codelineno-39-4" href="#__codelineno-39-4"></a><span class="c1">#SBATCH -n 1                 # nr. tasks  </span>
</span><span id="__span-39-5"><a id="__codelineno-39-5" name="__codelineno-39-5" href="#__codelineno-39-5"></a><span class="c1">#SBATCH -c 32                # nr. cores</span>
</span><span id="__span-39-6"><a id="__codelineno-39-6" name="__codelineno-39-6" href="#__codelineno-39-6"></a><span class="c1">#SBATCH --gpus-per-task=1    # nr. GPU cards</span>
</span><span id="__span-39-7"><a id="__codelineno-39-7" name="__codelineno-39-7" href="#__codelineno-39-7"></a><span class="c1">#SBATCH --time=00:04:00      # requested time</span>
</span><span id="__span-39-8"><a id="__codelineno-39-8" name="__codelineno-39-8" href="#__codelineno-39-8"></a><span class="c1">#SBATCH --error=job.%J.err   # error file</span>
</span><span id="__span-39-9"><a id="__codelineno-39-9" name="__codelineno-39-9" href="#__codelineno-39-9"></a><span class="c1">#SBATCH --output=job.%J.out  # output file            </span>
</span><span id="__span-39-10"><a id="__codelineno-39-10" name="__codelineno-39-10" href="#__codelineno-39-10"></a>
</span><span id="__span-39-11"><a id="__codelineno-39-11" name="__codelineno-39-11" href="#__codelineno-39-11"></a>ml<span class="w"> </span>buildenv-gcccuda/11.6.2-gcc9-hpc1<span class="w"> </span>
</span><span id="__span-39-12"><a id="__codelineno-39-12" name="__codelineno-39-12" href="#__codelineno-39-12"></a>ml<span class="w"> </span>julia/1.9.4-bdist
</span><span id="__span-39-13"><a id="__codelineno-39-13" name="__codelineno-39-13" href="#__codelineno-39-13"></a>
</span><span id="__span-39-14"><a id="__codelineno-39-14" name="__codelineno-39-14" href="#__codelineno-39-14"></a>julia<span class="w"> </span>script-gpu.jl
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p>Julia GPU example code.</p>
<div class="language-julia highlight"><pre><span></span><code><span id="__span-40-1"><a id="__codelineno-40-1" name="__codelineno-40-1" href="#__codelineno-40-1"></a><span class="k">using</span><span class="w"> </span><span class="n">CUDA</span><span class="w"> </span>
</span><span id="__span-40-2"><a id="__codelineno-40-2" name="__codelineno-40-2" href="#__codelineno-40-2"></a>
</span><span id="__span-40-3"><a id="__codelineno-40-3" name="__codelineno-40-3" href="#__codelineno-40-3"></a><span class="n">CUDA</span><span class="o">.</span><span class="n">versioninfo</span><span class="p">()</span>
</span><span id="__span-40-4"><a id="__codelineno-40-4" name="__codelineno-40-4" href="#__codelineno-40-4"></a>
</span><span id="__span-40-5"><a id="__codelineno-40-5" name="__codelineno-40-5" href="#__codelineno-40-5"></a><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">8</span>
</span><span id="__span-40-6"><a id="__codelineno-40-6" name="__codelineno-40-6" href="#__codelineno-40-6"></a><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">)</span>
</span><span id="__span-40-7"><a id="__codelineno-40-7" name="__codelineno-40-7" href="#__codelineno-40-7"></a><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">)</span>
</span><span id="__span-40-8"><a id="__codelineno-40-8" name="__codelineno-40-8" href="#__codelineno-40-8"></a>
</span><span id="__span-40-9"><a id="__codelineno-40-9" name="__codelineno-40-9" href="#__codelineno-40-9"></a><span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CuArray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-40-10"><a id="__codelineno-40-10" name="__codelineno-40-10" href="#__codelineno-40-10"></a><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CuArray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="__span-40-11"><a id="__codelineno-40-11" name="__codelineno-40-11" href="#__codelineno-40-11"></a>
</span><span id="__span-40-12"><a id="__codelineno-40-12" name="__codelineno-40-12" href="#__codelineno-40-12"></a><span class="c"># Calculation on CPU</span>
</span><span id="__span-40-13"><a id="__codelineno-40-13" name="__codelineno-40-13" href="#__codelineno-40-13"></a><span class="nd">@time</span><span class="w"> </span><span class="n">x</span><span class="o">*</span><span class="n">y</span>
</span><span id="__span-40-14"><a id="__codelineno-40-14" name="__codelineno-40-14" href="#__codelineno-40-14"></a><span class="c"># Calculation on GPU</span>
</span><span id="__span-40-15"><a id="__codelineno-40-15" name="__codelineno-40-15" href="#__codelineno-40-15"></a><span class="nd">@time</span><span class="w"> </span><span class="n">A</span><span class="o">*</span><span class="n">B</span>
</span><span id="__span-40-16"><a id="__codelineno-40-16" name="__codelineno-40-16" href="#__codelineno-40-16"></a>
</span><span id="__span-40-17"><a id="__codelineno-40-17" name="__codelineno-40-17" href="#__codelineno-40-17"></a><span class="c"># Calculation on CPU</span>
</span><span id="__span-40-18"><a id="__codelineno-40-18" name="__codelineno-40-18" href="#__codelineno-40-18"></a><span class="nd">@time</span><span class="w"> </span><span class="n">x</span><span class="o">*</span><span class="n">y</span>
</span><span id="__span-40-19"><a id="__codelineno-40-19" name="__codelineno-40-19" href="#__codelineno-40-19"></a><span class="c"># Calculation on GPU</span>
</span><span id="__span-40-20"><a id="__codelineno-40-20" name="__codelineno-40-20" href="#__codelineno-40-20"></a><span class="nd">@time</span><span class="w"> </span><span class="n">A</span><span class="o">*</span><span class="n">B</span>
</span></code></pre></div>
</div>
</div>
</div>
</div>
<div class="admonition important">
<p class="admonition-title">Running on AMD GPUs</p>
<div class="tabbed-set tabbed-alternate" data-tabs="7:2"><input checked="checked" id="__tabbed_7_1" name="__tabbed_7" type="radio" /><input id="__tabbed_7_2" name="__tabbed_7" type="radio" /><div class="tabbed-labels"><label for="__tabbed_7_1">PDC</label><label for="__tabbed_7_2">script-gpu.jl</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span id="__span-41-1"><a id="__codelineno-41-1" name="__codelineno-41-1" href="#__codelineno-41-1"></a><span class="ch">#!/bin/bash            </span>
</span><span id="__span-41-2"><a id="__codelineno-41-2" name="__codelineno-41-2" href="#__codelineno-41-2"></a><span class="c1">#SBATCH -A naiss202t-uv-wxyz # your project_ID       </span>
</span><span id="__span-41-3"><a id="__codelineno-41-3" name="__codelineno-41-3" href="#__codelineno-41-3"></a><span class="c1">#SBATCH -J job               # name of the job          </span>
</span><span id="__span-41-4"><a id="__codelineno-41-4" name="__codelineno-41-4" href="#__codelineno-41-4"></a><span class="c1">#SBATCH  -p gpu              # name of the queue</span>
</span><span id="__span-41-5"><a id="__codelineno-41-5" name="__codelineno-41-5" href="#__codelineno-41-5"></a><span class="c1">#SBATCH  --ntasks=1          # nr. of tasks</span>
</span><span id="__span-41-6"><a id="__codelineno-41-6" name="__codelineno-41-6" href="#__codelineno-41-6"></a><span class="c1">#SBATCH --cpus-per-task=1    # nr. of cores per-task</span>
</span><span id="__span-41-7"><a id="__codelineno-41-7" name="__codelineno-41-7" href="#__codelineno-41-7"></a><span class="c1">#SBATCH --time=00:03:00      # requested time</span>
</span><span id="__span-41-8"><a id="__codelineno-41-8" name="__codelineno-41-8" href="#__codelineno-41-8"></a><span class="c1">#SBATCH --error=job.%J.err   # error file</span>
</span><span id="__span-41-9"><a id="__codelineno-41-9" name="__codelineno-41-9" href="#__codelineno-41-9"></a><span class="c1">#SBATCH --output=job.%J.out  # output file                                                                                             </span>
</span><span id="__span-41-10"><a id="__codelineno-41-10" name="__codelineno-41-10" href="#__codelineno-41-10"></a><span class="c1"># Load dependencies and Julia version</span>
</span><span id="__span-41-11"><a id="__codelineno-41-11" name="__codelineno-41-11" href="#__codelineno-41-11"></a>ml<span class="w"> </span>PDC/23.12<span class="w"> </span>julia/1.10.2-cpeGNU-23.12<span class="w"> </span>
</span><span id="__span-41-12"><a id="__codelineno-41-12" name="__codelineno-41-12" href="#__codelineno-41-12"></a><span class="c1"># ROCM toolkit module</span>
</span><span id="__span-41-13"><a id="__codelineno-41-13" name="__codelineno-41-13" href="#__codelineno-41-13"></a>ml<span class="w"> </span>rocm/5.7.0<span class="w">  </span>craype-accel-amd-gfx90a<span class="w">   </span>
</span><span id="__span-41-14"><a id="__codelineno-41-14" name="__codelineno-41-14" href="#__codelineno-41-14"></a>
</span><span id="__span-41-15"><a id="__codelineno-41-15" name="__codelineno-41-15" href="#__codelineno-41-15"></a>julia<span class="w"> </span>script-gpu.jl
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p>Julia AMD GPU example code.</p>
<div class="language-julia highlight"><pre><span></span><code><span id="__span-42-1"><a id="__codelineno-42-1" name="__codelineno-42-1" href="#__codelineno-42-1"></a><span class="k">using</span><span class="w"> </span><span class="n">AMDGPU</span>
</span><span id="__span-42-2"><a id="__codelineno-42-2" name="__codelineno-42-2" href="#__codelineno-42-2"></a>
</span><span id="__span-42-3"><a id="__codelineno-42-3" name="__codelineno-42-3" href="#__codelineno-42-3"></a><span class="n">AMDGPU</span><span class="o">.</span><span class="n">versioninfo</span><span class="p">()</span><span class="w">  </span><span class="c"># Display AMD GPU information</span>
</span><span id="__span-42-4"><a id="__codelineno-42-4" name="__codelineno-42-4" href="#__codelineno-42-4"></a>
</span><span id="__span-42-5"><a id="__codelineno-42-5" name="__codelineno-42-5" href="#__codelineno-42-5"></a><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="o">^</span><span class="mi">8</span>
</span><span id="__span-42-6"><a id="__codelineno-42-6" name="__codelineno-42-6" href="#__codelineno-42-6"></a><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">)</span>
</span><span id="__span-42-7"><a id="__codelineno-42-7" name="__codelineno-42-7" href="#__codelineno-42-7"></a><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">)</span>
</span><span id="__span-42-8"><a id="__codelineno-42-8" name="__codelineno-42-8" href="#__codelineno-42-8"></a>
</span><span id="__span-42-9"><a id="__codelineno-42-9" name="__codelineno-42-9" href="#__codelineno-42-9"></a><span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROCArray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w">  </span><span class="c"># Transfer data to AMD GPU</span>
</span><span id="__span-42-10"><a id="__codelineno-42-10" name="__codelineno-42-10" href="#__codelineno-42-10"></a><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROCArray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="__span-42-11"><a id="__codelineno-42-11" name="__codelineno-42-11" href="#__codelineno-42-11"></a>
</span><span id="__span-42-12"><a id="__codelineno-42-12" name="__codelineno-42-12" href="#__codelineno-42-12"></a><span class="c"># Calculation on CPU</span>
</span><span id="__span-42-13"><a id="__codelineno-42-13" name="__codelineno-42-13" href="#__codelineno-42-13"></a><span class="nd">@time</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">y</span>
</span><span id="__span-42-14"><a id="__codelineno-42-14" name="__codelineno-42-14" href="#__codelineno-42-14"></a>
</span><span id="__span-42-15"><a id="__codelineno-42-15" name="__codelineno-42-15" href="#__codelineno-42-15"></a><span class="c"># Calculation on AMD GPU</span>
</span><span id="__span-42-16"><a id="__codelineno-42-16" name="__codelineno-42-16" href="#__codelineno-42-16"></a><span class="nd">@time</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">B</span>
</span><span id="__span-42-17"><a id="__codelineno-42-17" name="__codelineno-42-17" href="#__codelineno-42-17"></a>
</span><span id="__span-42-18"><a id="__codelineno-42-18" name="__codelineno-42-18" href="#__codelineno-42-18"></a><span class="c"># Calculation on CPU (again)</span>
</span><span id="__span-42-19"><a id="__codelineno-42-19" name="__codelineno-42-19" href="#__codelineno-42-19"></a><span class="nd">@time</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">y</span>
</span><span id="__span-42-20"><a id="__codelineno-42-20" name="__codelineno-42-20" href="#__codelineno-42-20"></a>
</span><span id="__span-42-21"><a id="__codelineno-42-21" name="__codelineno-42-21" href="#__codelineno-42-21"></a><span class="c"># Calculation on AMD GPU (again)</span>
</span><span id="__span-42-22"><a id="__codelineno-42-22" name="__codelineno-42-22" href="#__codelineno-42-22"></a><span class="nd">@time</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">B</span>
</span></code></pre></div>
</div>
</div>
</div>
</div>
<h4 id="julia-exercises">Julia Exercises<a class="headerlink" href="#julia-exercises" title="Anchor link to this section for reference">&para;</a></h4>
<div class="admonition example">
<p class="admonition-title"><strong>Exercise 1.</strong> Run the GPU script</p>
<p>Run the following script <code>script-gpu.jl</code>. Why are we running the simulations
twice?
Note that at UPPMAX you will need a project will access to Snowy. Remember that at PDC
we will use AMD GPUs.</p>
</div>
<details class="hint">
<summary>Answer</summary>
<div class="tabbed-set tabbed-alternate" data-tabs="8:5"><input checked="checked" id="__tabbed_8_1" name="__tabbed_8" type="radio" /><input id="__tabbed_8_2" name="__tabbed_8" type="radio" /><input id="__tabbed_8_3" name="__tabbed_8" type="radio" /><input id="__tabbed_8_4" name="__tabbed_8" type="radio" /><input id="__tabbed_8_5" name="__tabbed_8" type="radio" /><div class="tabbed-labels"><label for="__tabbed_8_1">HPC2N</label><label for="__tabbed_8_2">UPPMAX</label><label for="__tabbed_8_3">LUNARC</label><label for="__tabbed_8_4">PDC</label><label for="__tabbed_8_5">NSC</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>This batch script is for Kebnekaise. We run the simulation twice because
in this way, the reported time is more reliable for the computing time as
in the first simulation, data transfer and other settings could be added to
the reported time.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-43-1"><a id="__codelineno-43-1" name="__codelineno-43-1" href="#__codelineno-43-1"></a><span class="ch">#!/bin/bash            </span>
</span><span id="__span-43-2"><a id="__codelineno-43-2" name="__codelineno-43-2" href="#__codelineno-43-2"></a><span class="c1">#SBATCH -A hpc2n202w-xyz     # your project_ID       </span>
</span><span id="__span-43-3"><a id="__codelineno-43-3" name="__codelineno-43-3" href="#__codelineno-43-3"></a><span class="c1">#SBATCH -J job-serial        # name of the job         </span>
</span><span id="__span-43-4"><a id="__codelineno-43-4" name="__codelineno-43-4" href="#__codelineno-43-4"></a><span class="c1">#SBATCH -n 1                 # nr. tasks  </span>
</span><span id="__span-43-5"><a id="__codelineno-43-5" name="__codelineno-43-5" href="#__codelineno-43-5"></a><span class="c1">#SBATCH --time=00:03:00      # requested time</span>
</span><span id="__span-43-6"><a id="__codelineno-43-6" name="__codelineno-43-6" href="#__codelineno-43-6"></a><span class="c1">#SBATCH --error=job.%J.err   # error file</span>
</span><span id="__span-43-7"><a id="__codelineno-43-7" name="__codelineno-43-7" href="#__codelineno-43-7"></a><span class="c1">#SBATCH --output=job.%J.out  # output file  </span>
</span><span id="__span-43-8"><a id="__codelineno-43-8" name="__codelineno-43-8" href="#__codelineno-43-8"></a><span class="c1">#SBATCH --gres=gpu:v100:1     # 1 GPU v100 card</span>
</span><span id="__span-43-9"><a id="__codelineno-43-9" name="__codelineno-43-9" href="#__codelineno-43-9"></a>
</span><span id="__span-43-10"><a id="__codelineno-43-10" name="__codelineno-43-10" href="#__codelineno-43-10"></a>ml<span class="w"> </span>purge<span class="w">  </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-43-11"><a id="__codelineno-43-11" name="__codelineno-43-11" href="#__codelineno-43-11"></a>ml<span class="w"> </span>Julia/1.8.5-linux-x86_64
</span><span id="__span-43-12"><a id="__codelineno-43-12" name="__codelineno-43-12" href="#__codelineno-43-12"></a>ml<span class="w"> </span>CUDA/11.4.1
</span><span id="__span-43-13"><a id="__codelineno-43-13" name="__codelineno-43-13" href="#__codelineno-43-13"></a>
</span><span id="__span-43-14"><a id="__codelineno-43-14" name="__codelineno-43-14" href="#__codelineno-43-14"></a>julia<span class="w"> </span>script-gpu.jl
</span><span id="__span-43-15"><a id="__codelineno-43-15" name="__codelineno-43-15" href="#__codelineno-43-15"></a>
</span><span id="__span-43-16"><a id="__codelineno-43-16" name="__codelineno-43-16" href="#__codelineno-43-16"></a>Output:
</span><span id="__span-43-17"><a id="__codelineno-43-17" name="__codelineno-43-17" href="#__codelineno-43-17"></a><span class="w">    </span><span class="m">0</span>.689096<span class="w"> </span>seconds<span class="w"> </span><span class="o">(</span><span class="m">2</span>.72<span class="w"> </span>M<span class="w"> </span>allocations:<span class="w"> </span><span class="m">132</span>.617<span class="w"> </span>MiB,<span class="w"> </span><span class="m">6</span>.27%<span class="w"> </span>gc<span class="w"> </span>time,<span class="w"> </span><span class="m">99</span>.62%<span class="w"> </span>compilation<span class="w"> </span><span class="nb">time</span><span class="o">)</span>
</span><span id="__span-43-18"><a id="__codelineno-43-18" name="__codelineno-43-18" href="#__codelineno-43-18"></a>
</span><span id="__span-43-19"><a id="__codelineno-43-19" name="__codelineno-43-19" href="#__codelineno-43-19"></a><span class="w">    </span><span class="m">1</span>.194153<span class="w"> </span>seconds<span class="w"> </span><span class="o">(</span><span class="m">1</span>.24<span class="w"> </span>M<span class="w"> </span>allocations:<span class="w"> </span><span class="m">62</span>.487<span class="w"> </span>MiB,<span class="w"> </span><span class="m">3</span>.41%<span class="w"> </span>gc<span class="w"> </span>time,<span class="w"> </span><span class="m">55</span>.13%<span class="w"> </span>compilation<span class="w"> </span><span class="nb">time</span><span class="o">)</span>
</span><span id="__span-43-20"><a id="__codelineno-43-20" name="__codelineno-43-20" href="#__codelineno-43-20"></a>
</span><span id="__span-43-21"><a id="__codelineno-43-21" name="__codelineno-43-21" href="#__codelineno-43-21"></a><span class="w">    </span><span class="m">0</span>.000933<span class="w"> </span>seconds<span class="w"> </span><span class="o">(</span><span class="m">2</span><span class="w"> </span>allocations:<span class="w"> </span><span class="m">512</span>.047<span class="w"> </span>KiB<span class="o">)</span>
</span><span id="__span-43-22"><a id="__codelineno-43-22" name="__codelineno-43-22" href="#__codelineno-43-22"></a>
</span><span id="__span-43-23"><a id="__codelineno-43-23" name="__codelineno-43-23" href="#__codelineno-43-23"></a><span class="w">    </span><span class="m">0</span>.000311<span class="w"> </span>seconds<span class="w"> </span><span class="o">(</span><span class="m">5</span><span class="w"> </span>allocations:<span class="w"> </span><span class="m">192</span><span class="w"> </span>bytes<span class="o">)</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p>This batch script is for UPPMAX. Adding the numbers 2 and 3.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-44-1"><a id="__codelineno-44-1" name="__codelineno-44-1" href="#__codelineno-44-1"></a><span class="ch">#!/bin/bash -l</span>
</span><span id="__span-44-2"><a id="__codelineno-44-2" name="__codelineno-44-2" href="#__codelineno-44-2"></a><span class="c1">#SBATCH -A naiss202t-uv-wxyz   # your project_ID  </span>
</span><span id="__span-44-3"><a id="__codelineno-44-3" name="__codelineno-44-3" href="#__codelineno-44-3"></a><span class="c1">#SBATCH -M snowy</span>
</span><span id="__span-44-4"><a id="__codelineno-44-4" name="__codelineno-44-4" href="#__codelineno-44-4"></a><span class="c1">#SBATCH -p node</span>
</span><span id="__span-44-5"><a id="__codelineno-44-5" name="__codelineno-44-5" href="#__codelineno-44-5"></a><span class="c1">#SBATCH --gres=gpu:1</span>
</span><span id="__span-44-6"><a id="__codelineno-44-6" name="__codelineno-44-6" href="#__codelineno-44-6"></a><span class="c1">#SBATCH -N 1</span>
</span><span id="__span-44-7"><a id="__codelineno-44-7" name="__codelineno-44-7" href="#__codelineno-44-7"></a><span class="c1">#SBATCH --job-name=juliaGPU         # create a short name for your job</span>
</span><span id="__span-44-8"><a id="__codelineno-44-8" name="__codelineno-44-8" href="#__codelineno-44-8"></a><span class="c1">#SBATCH --time=00:15:00          # total run time limit (HH:MM:SS)</span>
</span><span id="__span-44-9"><a id="__codelineno-44-9" name="__codelineno-44-9" href="#__codelineno-44-9"></a><span class="c1">#SBATCH --qos=short              # if test run t&lt;15 min</span>
</span><span id="__span-44-10"><a id="__codelineno-44-10" name="__codelineno-44-10" href="#__codelineno-44-10"></a>
</span><span id="__span-44-11"><a id="__codelineno-44-11" name="__codelineno-44-11" href="#__codelineno-44-11"></a>ml<span class="w"> </span>julia/1.8.5
</span><span id="__span-44-12"><a id="__codelineno-44-12" name="__codelineno-44-12" href="#__codelineno-44-12"></a>
</span><span id="__span-44-13"><a id="__codelineno-44-13" name="__codelineno-44-13" href="#__codelineno-44-13"></a>julia<span class="w"> </span>script-gpu.jl
</span><span id="__span-44-14"><a id="__codelineno-44-14" name="__codelineno-44-14" href="#__codelineno-44-14"></a>
</span><span id="__span-44-15"><a id="__codelineno-44-15" name="__codelineno-44-15" href="#__codelineno-44-15"></a>Output:
</span><span id="__span-44-16"><a id="__codelineno-44-16" name="__codelineno-44-16" href="#__codelineno-44-16"></a>
</span><span id="__span-44-17"><a id="__codelineno-44-17" name="__codelineno-44-17" href="#__codelineno-44-17"></a>Downloading<span class="w"> </span>artifact:<span class="w"> </span>CUDNN
</span><span id="__span-44-18"><a id="__codelineno-44-18" name="__codelineno-44-18" href="#__codelineno-44-18"></a>Downloading<span class="w"> </span>artifact:<span class="w"> </span>CUTENSOR
</span><span id="__span-44-19"><a id="__codelineno-44-19" name="__codelineno-44-19" href="#__codelineno-44-19"></a>CUDA<span class="w"> </span>toolkit<span class="w"> </span><span class="m">11</span>.7,<span class="w"> </span>artifact<span class="w"> </span>installation
</span><span id="__span-44-20"><a id="__codelineno-44-20" name="__codelineno-44-20" href="#__codelineno-44-20"></a>NVIDIA<span class="w"> </span>driver<span class="w"> </span><span class="m">525</span>.85.12,<span class="w"> </span><span class="k">for</span><span class="w"> </span>CUDA<span class="w"> </span><span class="m">12</span>.0
</span><span id="__span-44-21"><a id="__codelineno-44-21" name="__codelineno-44-21" href="#__codelineno-44-21"></a>CUDA<span class="w"> </span>driver<span class="w"> </span><span class="m">12</span>.0
</span><span id="__span-44-22"><a id="__codelineno-44-22" name="__codelineno-44-22" href="#__codelineno-44-22"></a>
</span><span id="__span-44-23"><a id="__codelineno-44-23" name="__codelineno-44-23" href="#__codelineno-44-23"></a>Libraries:
</span><span id="__span-44-24"><a id="__codelineno-44-24" name="__codelineno-44-24" href="#__codelineno-44-24"></a>-<span class="w"> </span>CUBLAS:<span class="w"> </span><span class="m">11</span>.10.1
</span><span id="__span-44-25"><a id="__codelineno-44-25" name="__codelineno-44-25" href="#__codelineno-44-25"></a>-<span class="w"> </span>CURAND:<span class="w"> </span><span class="m">10</span>.2.10
</span><span id="__span-44-26"><a id="__codelineno-44-26" name="__codelineno-44-26" href="#__codelineno-44-26"></a>-<span class="w"> </span>CUFFT:<span class="w"> </span><span class="m">10</span>.7.2
</span><span id="__span-44-27"><a id="__codelineno-44-27" name="__codelineno-44-27" href="#__codelineno-44-27"></a>-<span class="w"> </span>CUSOLVER:<span class="w"> </span><span class="m">11</span>.3.5
</span><span id="__span-44-28"><a id="__codelineno-44-28" name="__codelineno-44-28" href="#__codelineno-44-28"></a>-<span class="w"> </span>CUSPARSE:<span class="w"> </span><span class="m">11</span>.7.3
</span><span id="__span-44-29"><a id="__codelineno-44-29" name="__codelineno-44-29" href="#__codelineno-44-29"></a>-<span class="w"> </span>CUPTI:<span class="w"> </span><span class="m">17</span>.0.0
</span><span id="__span-44-30"><a id="__codelineno-44-30" name="__codelineno-44-30" href="#__codelineno-44-30"></a>-<span class="w"> </span>NVML:<span class="w"> </span><span class="m">12</span>.0.0+525.85.12
</span><span id="__span-44-31"><a id="__codelineno-44-31" name="__codelineno-44-31" href="#__codelineno-44-31"></a>-<span class="w"> </span>CUDNN:<span class="w"> </span><span class="m">8</span>.30.2<span class="w"> </span><span class="o">(</span><span class="k">for</span><span class="w"> </span>CUDA<span class="w"> </span><span class="m">11</span>.5.0<span class="o">)</span>
</span><span id="__span-44-32"><a id="__codelineno-44-32" name="__codelineno-44-32" href="#__codelineno-44-32"></a>-<span class="w"> </span>CUTENSOR:<span class="w"> </span><span class="m">1</span>.4.0<span class="w"> </span><span class="o">(</span><span class="k">for</span><span class="w"> </span>CUDA<span class="w"> </span><span class="m">11</span>.5.0<span class="o">)</span>
</span><span id="__span-44-33"><a id="__codelineno-44-33" name="__codelineno-44-33" href="#__codelineno-44-33"></a>
</span><span id="__span-44-34"><a id="__codelineno-44-34" name="__codelineno-44-34" href="#__codelineno-44-34"></a>Toolchain:
</span><span id="__span-44-35"><a id="__codelineno-44-35" name="__codelineno-44-35" href="#__codelineno-44-35"></a>-<span class="w"> </span>Julia:<span class="w"> </span><span class="m">1</span>.8.5
</span><span id="__span-44-36"><a id="__codelineno-44-36" name="__codelineno-44-36" href="#__codelineno-44-36"></a>-<span class="w"> </span>LLVM:<span class="w"> </span><span class="m">13</span>.0.1
</span><span id="__span-44-37"><a id="__codelineno-44-37" name="__codelineno-44-37" href="#__codelineno-44-37"></a>-<span class="w"> </span>PTX<span class="w"> </span>ISA<span class="w"> </span>support:<span class="w"> </span><span class="m">3</span>.2,<span class="w"> </span><span class="m">4</span>.0,<span class="w"> </span><span class="m">4</span>.1,<span class="w"> </span><span class="m">4</span>.2,<span class="w"> </span><span class="m">4</span>.3,<span class="w"> </span><span class="m">5</span>.0,<span class="w"> </span><span class="m">6</span>.0,<span class="w"> </span><span class="m">6</span>.1,<span class="w"> </span><span class="m">6</span>.3,<span class="w"> </span><span class="m">6</span>.4,<span class="w"> </span><span class="m">6</span>.5,<span class="w"> </span><span class="m">7</span>.0,<span class="w"> </span><span class="m">7</span>.1,<span class="w"> </span><span class="m">7</span>.2
</span><span id="__span-44-38"><a id="__codelineno-44-38" name="__codelineno-44-38" href="#__codelineno-44-38"></a>-<span class="w"> </span>Device<span class="w"> </span>capability<span class="w"> </span>support:<span class="w"> </span>sm_35,<span class="w"> </span>sm_37,<span class="w"> </span>sm_50,<span class="w"> </span>sm_52,<span class="w"> </span>sm_53,<span class="w"> </span>sm_60,<span class="w"> </span>sm_61,<span class="w"> </span>sm_62,<span class="w"> </span>sm_70,<span class="w"> </span>sm_72,<span class="w"> </span>sm_75,<span class="w"> </span>sm_80,<span class="w"> </span>sm_86
</span><span id="__span-44-39"><a id="__codelineno-44-39" name="__codelineno-44-39" href="#__codelineno-44-39"></a>
</span><span id="__span-44-40"><a id="__codelineno-44-40" name="__codelineno-44-40" href="#__codelineno-44-40"></a><span class="m">1</span><span class="w"> </span>device:
</span><span id="__span-44-41"><a id="__codelineno-44-41" name="__codelineno-44-41" href="#__codelineno-44-41"></a><span class="w">    </span><span class="m">0</span>:<span class="w"> </span>Tesla<span class="w"> </span>T4<span class="w"> </span><span class="o">(</span>sm_75,<span class="w"> </span><span class="m">14</span>.605<span class="w"> </span>GiB<span class="w"> </span>/<span class="w"> </span><span class="m">15</span>.000<span class="w"> </span>GiB<span class="w"> </span>available<span class="o">)</span>
</span><span id="__span-44-42"><a id="__codelineno-44-42" name="__codelineno-44-42" href="#__codelineno-44-42"></a><span class="w">    </span><span class="m">0</span>.988437<span class="w"> </span>seconds<span class="w"> </span><span class="o">(</span><span class="m">2</span>.72<span class="w"> </span>M<span class="w"> </span>allocations:<span class="w"> </span><span class="m">132</span>.556<span class="w"> </span>MiB,<span class="w"> </span><span class="m">4</span>.72%<span class="w"> </span>gc<span class="w"> </span>time,<span class="w"> </span><span class="m">99</span>.10%<span class="w"> </span>compilation<span class="w"> </span><span class="nb">time</span><span class="o">)</span>
</span><span id="__span-44-43"><a id="__codelineno-44-43" name="__codelineno-44-43" href="#__codelineno-44-43"></a><span class="w">    </span><span class="m">5</span>.707402<span class="w"> </span>seconds<span class="w"> </span><span class="o">(</span><span class="m">1</span>.30<span class="w"> </span>M<span class="w"> </span>allocations:<span class="w"> </span><span class="m">65</span>.564<span class="w"> </span>MiB,<span class="w"> </span><span class="m">0</span>.72%<span class="w"> </span>gc<span class="w"> </span>time,<span class="w"> </span><span class="m">19</span>.70%<span class="w"> </span>compilation<span class="w"> </span><span class="nb">time</span><span class="o">)</span>
</span><span id="__span-44-44"><a id="__codelineno-44-44" name="__codelineno-44-44" href="#__codelineno-44-44"></a><span class="w">    </span><span class="m">0</span>.000813<span class="w"> </span>seconds<span class="w"> </span><span class="o">(</span><span class="m">2</span><span class="w"> </span>allocations:<span class="w"> </span><span class="m">512</span>.047<span class="w"> </span>KiB<span class="o">)</span>
</span><span id="__span-44-45"><a id="__codelineno-44-45" name="__codelineno-44-45" href="#__codelineno-44-45"></a><span class="w">    </span><span class="m">0</span>.000176<span class="w"> </span>seconds<span class="w"> </span><span class="o">(</span><span class="m">16</span><span class="w"> </span>allocations:<span class="w"> </span><span class="m">384</span><span class="w"> </span>bytes<span class="o">)</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p>This batch script is for Cosmos.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-45-1"><a id="__codelineno-45-1" name="__codelineno-45-1" href="#__codelineno-45-1"></a><span class="ch">#!/bin/bash            </span>
</span><span id="__span-45-2"><a id="__codelineno-45-2" name="__codelineno-45-2" href="#__codelineno-45-2"></a><span class="c1">#SBATCH -A lu202w-x-yz       # your project_ID       </span>
</span><span id="__span-45-3"><a id="__codelineno-45-3" name="__codelineno-45-3" href="#__codelineno-45-3"></a><span class="c1">#SBATCH -J job-serial        # name of the job         </span>
</span><span id="__span-45-4"><a id="__codelineno-45-4" name="__codelineno-45-4" href="#__codelineno-45-4"></a><span class="c1">#SBATCH -n 1                 # nr. tasks  </span>
</span><span id="__span-45-5"><a id="__codelineno-45-5" name="__codelineno-45-5" href="#__codelineno-45-5"></a><span class="c1">#SBATCH --time=00:03:00      # requested time</span>
</span><span id="__span-45-6"><a id="__codelineno-45-6" name="__codelineno-45-6" href="#__codelineno-45-6"></a><span class="c1">#SBATCH --error=job.%J.err   # error file</span>
</span><span id="__span-45-7"><a id="__codelineno-45-7" name="__codelineno-45-7" href="#__codelineno-45-7"></a><span class="c1">#SBATCH --output=job.%J.out  # output file  </span>
</span><span id="__span-45-8"><a id="__codelineno-45-8" name="__codelineno-45-8" href="#__codelineno-45-8"></a><span class="c1">#Asking for one A100 GPU</span>
</span><span id="__span-45-9"><a id="__codelineno-45-9" name="__codelineno-45-9" href="#__codelineno-45-9"></a><span class="c1">#SBATCH -p gpua100</span>
</span><span id="__span-45-10"><a id="__codelineno-45-10" name="__codelineno-45-10" href="#__codelineno-45-10"></a><span class="c1">#SBATCH --gres=gpu:1   </span>
</span><span id="__span-45-11"><a id="__codelineno-45-11" name="__codelineno-45-11" href="#__codelineno-45-11"></a>
</span><span id="__span-45-12"><a id="__codelineno-45-12" name="__codelineno-45-12" href="#__codelineno-45-12"></a>ml<span class="w"> </span>purge<span class="w">  </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
</span><span id="__span-45-13"><a id="__codelineno-45-13" name="__codelineno-45-13" href="#__codelineno-45-13"></a>ml<span class="w"> </span>Julia/1.8.5-linux-x86_64
</span><span id="__span-45-14"><a id="__codelineno-45-14" name="__codelineno-45-14" href="#__codelineno-45-14"></a>ml<span class="w"> </span>CUDA/11.4.1
</span><span id="__span-45-15"><a id="__codelineno-45-15" name="__codelineno-45-15" href="#__codelineno-45-15"></a>
</span><span id="__span-45-16"><a id="__codelineno-45-16" name="__codelineno-45-16" href="#__codelineno-45-16"></a>julia<span class="w"> </span>script-gpu.jl
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p>This batch script is for Dardel.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-46-1"><a id="__codelineno-46-1" name="__codelineno-46-1" href="#__codelineno-46-1"></a><span class="ch">#!/bin/bash</span>
</span><span id="__span-46-2"><a id="__codelineno-46-2" name="__codelineno-46-2" href="#__codelineno-46-2"></a><span class="c1">#SBATCH -A naiss202t-uv-wxyz # your project_ID       </span>
</span><span id="__span-46-3"><a id="__codelineno-46-3" name="__codelineno-46-3" href="#__codelineno-46-3"></a><span class="c1">#SBATCH -J job               # name of the job          </span>
</span><span id="__span-46-4"><a id="__codelineno-46-4" name="__codelineno-46-4" href="#__codelineno-46-4"></a><span class="c1">#SBATCH  -p gpu              # name of the queue</span>
</span><span id="__span-46-5"><a id="__codelineno-46-5" name="__codelineno-46-5" href="#__codelineno-46-5"></a><span class="c1">#SBATCH  --ntasks=1          # nr. of tasks</span>
</span><span id="__span-46-6"><a id="__codelineno-46-6" name="__codelineno-46-6" href="#__codelineno-46-6"></a><span class="c1">#SBATCH --cpus-per-task=1    # nr. of cores per-task</span>
</span><span id="__span-46-7"><a id="__codelineno-46-7" name="__codelineno-46-7" href="#__codelineno-46-7"></a><span class="c1">#SBATCH --time=00:03:00      # requested time</span>
</span><span id="__span-46-8"><a id="__codelineno-46-8" name="__codelineno-46-8" href="#__codelineno-46-8"></a><span class="c1">#SBATCH --error=job.%J.err   # error file</span>
</span><span id="__span-46-9"><a id="__codelineno-46-9" name="__codelineno-46-9" href="#__codelineno-46-9"></a><span class="c1">#SBATCH --output=job.%J.out  # output file                                                                                                                                                                         </span>
</span><span id="__span-46-10"><a id="__codelineno-46-10" name="__codelineno-46-10" href="#__codelineno-46-10"></a>
</span><span id="__span-46-11"><a id="__codelineno-46-11" name="__codelineno-46-11" href="#__codelineno-46-11"></a><span class="c1"># Load dependencies and Julia version</span>
</span><span id="__span-46-12"><a id="__codelineno-46-12" name="__codelineno-46-12" href="#__codelineno-46-12"></a>ml<span class="w"> </span>PDC/23.12<span class="w"> </span>julia/1.10.2-cpeGNU-23.12<span class="w"> </span>
</span><span id="__span-46-13"><a id="__codelineno-46-13" name="__codelineno-46-13" href="#__codelineno-46-13"></a><span class="c1"># ROCM toolkit module</span>
</span><span id="__span-46-14"><a id="__codelineno-46-14" name="__codelineno-46-14" href="#__codelineno-46-14"></a>ml<span class="w"> </span>rocm/5.7.0<span class="w">  </span>craype-accel-amd-gfx90a<span class="w">   </span>
</span><span id="__span-46-15"><a id="__codelineno-46-15" name="__codelineno-46-15" href="#__codelineno-46-15"></a>
</span><span id="__span-46-16"><a id="__codelineno-46-16" name="__codelineno-46-16" href="#__codelineno-46-16"></a>julia<span class="w"> </span>script-gpu.jl<span class="w">                </span>
</span><span id="__span-46-17"><a id="__codelineno-46-17" name="__codelineno-46-17" href="#__codelineno-46-17"></a>
</span><span id="__span-46-18"><a id="__codelineno-46-18" name="__codelineno-46-18" href="#__codelineno-46-18"></a>OUTPUT:
</span><span id="__span-46-19"><a id="__codelineno-46-19" name="__codelineno-46-19" href="#__codelineno-46-19"></a>
</span><span id="__span-46-20"><a id="__codelineno-46-20" name="__codelineno-46-20" href="#__codelineno-46-20"></a>┌───────────┬──────────────────┬─...
</span><span id="__span-46-21"><a id="__codelineno-46-21" name="__codelineno-46-21" href="#__codelineno-46-21"></a>│<span class="w"> </span>Available<span class="w"> </span>│<span class="w"> </span>Name<span class="w">             </span>│<span class="w"> </span>...
</span><span id="__span-46-22"><a id="__codelineno-46-22" name="__codelineno-46-22" href="#__codelineno-46-22"></a>├───────────┼──────────────────┼─...
</span><span id="__span-46-23"><a id="__codelineno-46-23" name="__codelineno-46-23" href="#__codelineno-46-23"></a>│<span class="w">     </span>+<span class="w">     </span>│<span class="w"> </span>LLD<span class="w">              </span>│<span class="w"> </span>...
</span><span id="__span-46-24"><a id="__codelineno-46-24" name="__codelineno-46-24" href="#__codelineno-46-24"></a>│<span class="w">     </span>+<span class="w">     </span>│<span class="w"> </span>Device<span class="w"> </span>Libraries<span class="w"> </span>│<span class="w"> </span>...
</span><span id="__span-46-25"><a id="__codelineno-46-25" name="__codelineno-46-25" href="#__codelineno-46-25"></a>│<span class="w">     </span>+<span class="w">     </span>│<span class="w"> </span>HIP<span class="w">              </span>│<span class="w"> </span>...
</span><span id="__span-46-26"><a id="__codelineno-46-26" name="__codelineno-46-26" href="#__codelineno-46-26"></a>│<span class="w">     </span>+<span class="w">     </span>│<span class="w"> </span>rocBLAS<span class="w">          </span>│<span class="w"> </span>...
</span><span id="__span-46-27"><a id="__codelineno-46-27" name="__codelineno-46-27" href="#__codelineno-46-27"></a>│<span class="w">     </span>+<span class="w">     </span>│<span class="w"> </span>rocSOLVER<span class="w">        </span>│<span class="w"> </span>...
</span><span id="__span-46-28"><a id="__codelineno-46-28" name="__codelineno-46-28" href="#__codelineno-46-28"></a>│<span class="w">     </span>+<span class="w">     </span>│<span class="w"> </span>rocSPARSE<span class="w">        </span>│<span class="w"> </span>...
</span><span id="__span-46-29"><a id="__codelineno-46-29" name="__codelineno-46-29" href="#__codelineno-46-29"></a>│<span class="w">     </span>+<span class="w">     </span>│<span class="w"> </span>rocRAND<span class="w">          </span>│<span class="w"> </span>...
</span><span id="__span-46-30"><a id="__codelineno-46-30" name="__codelineno-46-30" href="#__codelineno-46-30"></a>│<span class="w">     </span>+<span class="w">     </span>│<span class="w"> </span>rocFFT<span class="w">           </span>│<span class="w"> </span>...
</span><span id="__span-46-31"><a id="__codelineno-46-31" name="__codelineno-46-31" href="#__codelineno-46-31"></a>│<span class="w">     </span>+<span class="w">     </span>│<span class="w"> </span>MIOpen<span class="w">           </span>│<span class="w"> </span>...
</span><span id="__span-46-32"><a id="__codelineno-46-32" name="__codelineno-46-32" href="#__codelineno-46-32"></a>└───────────┴──────────────────┴─...
</span><span id="__span-46-33"><a id="__codelineno-46-33" name="__codelineno-46-33" href="#__codelineno-46-33"></a>
</span><span id="__span-46-34"><a id="__codelineno-46-34" name="__codelineno-46-34" href="#__codelineno-46-34"></a>┌────┬─────────────────────┬─────...
</span><span id="__span-46-35"><a id="__codelineno-46-35" name="__codelineno-46-35" href="#__codelineno-46-35"></a>│<span class="w"> </span>Id<span class="w"> </span>│<span class="w">                </span>Name<span class="w"> </span>│<span class="w">     </span>...
</span><span id="__span-46-36"><a id="__codelineno-46-36" name="__codelineno-46-36" href="#__codelineno-46-36"></a>├────┼─────────────────────┼─────...
</span><span id="__span-46-37"><a id="__codelineno-46-37" name="__codelineno-46-37" href="#__codelineno-46-37"></a>│<span class="w">  </span><span class="m">1</span><span class="w"> </span>│<span class="w"> </span>AMD<span class="w"> </span>Instinct<span class="w"> </span>MI250X<span class="w"> </span>│<span class="w"> </span>gfx9...
</span><span id="__span-46-38"><a id="__codelineno-46-38" name="__codelineno-46-38" href="#__codelineno-46-38"></a>│<span class="w">  </span><span class="m">2</span><span class="w"> </span>│<span class="w"> </span>AMD<span class="w"> </span>Instinct<span class="w"> </span>MI250X<span class="w"> </span>│<span class="w"> </span>gfx9...
</span><span id="__span-46-39"><a id="__codelineno-46-39" name="__codelineno-46-39" href="#__codelineno-46-39"></a>│<span class="w">  </span><span class="m">3</span><span class="w"> </span>│<span class="w"> </span>AMD<span class="w"> </span>Instinct<span class="w"> </span>MI250X<span class="w"> </span>│<span class="w"> </span>gfx9...
</span><span id="__span-46-40"><a id="__codelineno-46-40" name="__codelineno-46-40" href="#__codelineno-46-40"></a>│<span class="w">  </span><span class="m">4</span><span class="w"> </span>│<span class="w"> </span>AMD<span class="w"> </span>Instinct<span class="w"> </span>MI250X<span class="w"> </span>│<span class="w"> </span>gfx9...
</span><span id="__span-46-41"><a id="__codelineno-46-41" name="__codelineno-46-41" href="#__codelineno-46-41"></a>│<span class="w">  </span><span class="m">5</span><span class="w"> </span>│<span class="w"> </span>AMD<span class="w"> </span>Instinct<span class="w"> </span>MI250X<span class="w"> </span>│<span class="w"> </span>gfx9...
</span><span id="__span-46-42"><a id="__codelineno-46-42" name="__codelineno-46-42" href="#__codelineno-46-42"></a>│<span class="w">  </span><span class="m">6</span><span class="w"> </span>│<span class="w"> </span>AMD<span class="w"> </span>Instinct<span class="w"> </span>MI250X<span class="w"> </span>│<span class="w"> </span>gfx9...
</span><span id="__span-46-43"><a id="__codelineno-46-43" name="__codelineno-46-43" href="#__codelineno-46-43"></a>│<span class="w">  </span><span class="m">7</span><span class="w"> </span>│<span class="w"> </span>AMD<span class="w"> </span>Instinct<span class="w"> </span>MI250X<span class="w"> </span>│<span class="w"> </span>gfx9...
</span><span id="__span-46-44"><a id="__codelineno-46-44" name="__codelineno-46-44" href="#__codelineno-46-44"></a>│<span class="w">  </span><span class="m">8</span><span class="w"> </span>│<span class="w"> </span>AMD<span class="w"> </span>Instinct<span class="w"> </span>MI250X<span class="w"> </span>│<span class="w"> </span>gfx9...
</span><span id="__span-46-45"><a id="__codelineno-46-45" name="__codelineno-46-45" href="#__codelineno-46-45"></a>└────┴─────────────────────┴─────...
</span><span id="__span-46-46"><a id="__codelineno-46-46" name="__codelineno-46-46" href="#__codelineno-46-46"></a>
</span><span id="__span-46-47"><a id="__codelineno-46-47" name="__codelineno-46-47" href="#__codelineno-46-47"></a><span class="m">1</span>.241600<span class="w"> </span>seconds<span class="w"> </span><span class="o">(</span><span class="m">2</span>.27<span class="w"> </span>M<span class="w"> </span>allocations:<span class="w"> </span><span class="m">152</span>.229<span class="w"> </span>MiB,<span class="w"> </span><span class="m">8</span>.28%<span class="w"> </span>gc<span class="w"> </span>time,<span class="w"> </span><span class="m">91</span>.71%<span class="w"> </span>compilation<span class="w"> </span><span class="nb">time</span><span class="o">)</span>
</span><span id="__span-46-48"><a id="__codelineno-46-48" name="__codelineno-46-48" href="#__codelineno-46-48"></a><span class="m">0</span>.604009<span class="w"> </span>seconds<span class="w"> </span><span class="o">(</span><span class="m">624</span>.95<span class="w"> </span>k<span class="w"> </span>allocations:<span class="w"> </span><span class="m">38</span>.360<span class="w"> </span>MiB,<span class="w"> </span><span class="m">68</span>.01%<span class="w"> </span>compilation<span class="w"> </span><span class="nb">time</span><span class="o">)</span>
</span><span id="__span-46-49"><a id="__codelineno-46-49" name="__codelineno-46-49" href="#__codelineno-46-49"></a><span class="m">0</span>.001051<span class="w"> </span>seconds<span class="w"> </span><span class="o">(</span><span class="m">2</span><span class="w"> </span>allocations:<span class="w"> </span><span class="m">512</span>.047<span class="w"> </span>KiB<span class="o">)</span>
</span><span id="__span-46-50"><a id="__codelineno-46-50" name="__codelineno-46-50" href="#__codelineno-46-50"></a><span class="m">0</span>.000077<span class="w"> </span>seconds<span class="w"> </span><span class="o">(</span><span class="m">13</span><span class="w"> </span>allocations:<span class="w"> </span><span class="m">352</span><span class="w"> </span>bytes<span class="o">)</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p>This batch script is for NSC. </p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-47-1"><a id="__codelineno-47-1" name="__codelineno-47-1" href="#__codelineno-47-1"></a><span class="ch">#!/bin/bash            </span>
</span><span id="__span-47-2"><a id="__codelineno-47-2" name="__codelineno-47-2" href="#__codelineno-47-2"></a><span class="c1">#SBATCH -A naiss202t-uv-wxyz # your project_ID </span>
</span><span id="__span-47-3"><a id="__codelineno-47-3" name="__codelineno-47-3" href="#__codelineno-47-3"></a><span class="c1">#SBATCH -J job-gpu           # name of the job         </span>
</span><span id="__span-47-4"><a id="__codelineno-47-4" name="__codelineno-47-4" href="#__codelineno-47-4"></a><span class="c1">#SBATCH -n 1                 # nr. tasks  </span>
</span><span id="__span-47-5"><a id="__codelineno-47-5" name="__codelineno-47-5" href="#__codelineno-47-5"></a><span class="c1">#SBATCH -c 32                # nr. cores</span>
</span><span id="__span-47-6"><a id="__codelineno-47-6" name="__codelineno-47-6" href="#__codelineno-47-6"></a><span class="c1">#SBATCH --gpus-per-task=1    # nr. GPU cards</span>
</span><span id="__span-47-7"><a id="__codelineno-47-7" name="__codelineno-47-7" href="#__codelineno-47-7"></a><span class="c1">#SBATCH --time=00:04:00      # requested time</span>
</span><span id="__span-47-8"><a id="__codelineno-47-8" name="__codelineno-47-8" href="#__codelineno-47-8"></a><span class="c1">#SBATCH --error=job.%J.err   # error file</span>
</span><span id="__span-47-9"><a id="__codelineno-47-9" name="__codelineno-47-9" href="#__codelineno-47-9"></a><span class="c1">#SBATCH --output=job.%J.out  # output file            </span>
</span><span id="__span-47-10"><a id="__codelineno-47-10" name="__codelineno-47-10" href="#__codelineno-47-10"></a>
</span><span id="__span-47-11"><a id="__codelineno-47-11" name="__codelineno-47-11" href="#__codelineno-47-11"></a>ml<span class="w"> </span>buildenv-gcccuda/11.6.2-gcc9-hpc1<span class="w"> </span>
</span><span id="__span-47-12"><a id="__codelineno-47-12" name="__codelineno-47-12" href="#__codelineno-47-12"></a>ml<span class="w"> </span>julia/1.9.4-bdist<span class="w">       </span>
</span><span id="__span-47-13"><a id="__codelineno-47-13" name="__codelineno-47-13" href="#__codelineno-47-13"></a>
</span><span id="__span-47-14"><a id="__codelineno-47-14" name="__codelineno-47-14" href="#__codelineno-47-14"></a>julia<span class="w"> </span>script-gpu.jl<span class="w">     </span>
</span></code></pre></div>
</div>
</div>
</div>
</details>
<div class="admonition summary">
<p class="admonition-title">Summary</p>
<ul>
<li>GPUs process simple functions rapidly, and are best suited for repetitive and highly-parallel computing tasks</li>
<li>There are GPUs on NSC/Tetralith, PDC/Dardel, C3SE/Alvis, HPC2N/Kebnekaise, LUNARC/Cosmos, UPPMAX/Pelle, but they are different</li>
<li>It varies between centres how you allocate a GPU</li>
<li>You need to use either batch or interactive/OpenOnDemand to use GPUs</li>
</ul>
</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../big_data_managers/" class="btn btn-neutral float-left" title="Big data"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../ML/" class="btn btn-neutral float-right" title="Introduction">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/UPPMAX/R-matlab-julia-HPC" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../big_data_managers/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../ML/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../assets/_markdown_exec_pyodide.js"></script>
      <script src="../../js/popper.min.js"></script>
      <script src="../../js/tippy-bundle.umd.js"></script>
      <script src="../../js/clipboard.js"></script>
      <script src="../../js/extra.js"></script>
      <script src="../../search/main.js"></script>
      <script src="../../js/open_in_new_tab.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
